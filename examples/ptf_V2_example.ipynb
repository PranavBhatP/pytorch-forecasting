{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2630DaOEI4AJ",
    "outputId": "96798236-d2f1-4436-c047-49c3771d56c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-forecasting\n",
      "  Downloading pytorch_forecasting-1.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (2.0.2)\n",
      "Requirement already satisfied: torch!=2.0.1,<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (2.6.0+cu124)\n",
      "Collecting lightning<3.0.0,>=2.0.0 (from pytorch-forecasting)\n",
      "  Downloading lightning-2.5.1-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (1.14.1)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn<2.0,>=1.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (1.6.1)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.2)\n",
      "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2025.3.2)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (24.2)\n",
      "Collecting torchmetrics<3.0,>=0.7.0 (from lightning<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Downloading torchmetrics-1.7.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.13.0)\n",
      "Collecting pytorch-lightning (from lightning<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Downloading pytorch_lightning-2.5.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (3.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.11.15)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (75.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch-forecasting) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.3.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.10)\n",
      "Downloading pytorch_forecasting-1.3.0-py3-none-any.whl (197 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.7/197.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning-2.5.1-py3-none-any.whl (818 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Downloading torchmetrics-1.7.0-py3-none-any.whl (960 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.9/960.9 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_lightning-2.5.1-py3-none-any.whl (822 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning, lightning, pytorch-forecasting\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed lightning-2.5.1 lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-forecasting-1.3.0 pytorch-lightning-2.5.1 torchmetrics-1.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "M7PQerTbI_tM"
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from pytorch_forecasting.data.timeseries import _coerce_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XmL5ukG9JDTD"
   },
   "outputs": [],
   "source": [
    "def _coerce_to_list(obj):\n",
    "    \"\"\"Coerce object to list.\n",
    "\n",
    "    None is coerced to empty list, otherwise list constructor is used.\n",
    "    \"\"\"\n",
    "    if obj is None:\n",
    "        return []\n",
    "    if isinstance(obj, str):\n",
    "        return [obj]\n",
    "    return list(obj)\n",
    "\n",
    "\n",
    "class TimeSeries(Dataset):\n",
    "    \"\"\"PyTorch Dataset for time series data stored in pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        data frame with sequence data.\n",
    "        Column names must all be str, and contain str as referred to below.\n",
    "    data_future : pd.DataFrame, optional, default=None\n",
    "        data frame with future data.\n",
    "        Column names must all be str, and contain str as referred to below.\n",
    "        May contain only columns that are in time, group, weight, known, or static.\n",
    "    time : str, optional, default = first col not in group_ids, weight, target, static.\n",
    "        integer typed column denoting the time index within ``data``.\n",
    "        This column is used to determine the sequence of samples.\n",
    "        If there are no missing observations,\n",
    "        the time index should increase by ``+1`` for each subsequent sample.\n",
    "        The first time_idx for each series does not necessarily\n",
    "        have to be ``0`` but any value is allowed.\n",
    "    target : str or List[str], optional, default = last column (at iloc -1)\n",
    "        column(s) in ``data`` denoting the forecasting target.\n",
    "        Can be categorical or numerical dtype.\n",
    "    group : List[str], optional, default = None\n",
    "        list of column names identifying a time series instance within ``data``.\n",
    "        This means that the ``group`` together uniquely identify an instance,\n",
    "        and ``group`` together with ``time`` uniquely identify a single observation\n",
    "        within a time series instance.\n",
    "        If ``None``, the dataset is assumed to be a single time series.\n",
    "    weight : str, optional, default=None\n",
    "        column name for weights.\n",
    "        If ``None``, it is assumed that there is no weight column.\n",
    "    num : list of str, optional, default = all columns with dtype in \"fi\"\n",
    "        list of numerical variables in ``data``,\n",
    "        list may also contain list of str, which are then grouped together.\n",
    "    cat : list of str, optional, default = all columns with dtype in \"Obc\"\n",
    "        list of categorical variables in ``data``,\n",
    "        list may also contain list of str, which are then grouped together\n",
    "        (e.g. useful for product categories).\n",
    "    known : list of str, optional, default = all variables\n",
    "        list of variables that change over time and are known in the future,\n",
    "        list may also contain list of str, which are then grouped together\n",
    "        (e.g. useful for special days or promotion categories).\n",
    "    unknown : list of str, optional, default = no variables\n",
    "        list of variables that are not known in the future,\n",
    "        list may also contain list of str, which are then grouped together\n",
    "        (e.g. useful for weather categories).\n",
    "    static : list of str, optional, default = all variables not in known, unknown\n",
    "        list of variables that do not change over time,\n",
    "        list may also contain list of str, which are then grouped together.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        data_future: Optional[pd.DataFrame] = None,\n",
    "        time: Optional[str] = None,\n",
    "        target: Optional[Union[str, List[str]]] = None,\n",
    "        group: Optional[List[str]] = None,\n",
    "        weight: Optional[str] = None,\n",
    "        num: Optional[List[Union[str, List[str]]]] = None,\n",
    "        cat: Optional[List[Union[str, List[str]]]] = None,\n",
    "        known: Optional[List[Union[str, List[str]]]] = None,\n",
    "        unknown: Optional[List[Union[str, List[str]]]] = None,\n",
    "        static: Optional[List[Union[str, List[str]]]] = None,\n",
    "    ):\n",
    "\n",
    "        self.data = data\n",
    "        self.data_future = data_future\n",
    "        self.time = time\n",
    "        self.target = _coerce_to_list(target)\n",
    "        self.group = _coerce_to_list(group)\n",
    "        self.weight = weight\n",
    "        self.num = _coerce_to_list(num)\n",
    "        self.cat = _coerce_to_list(cat)\n",
    "        self.known = _coerce_to_list(known)\n",
    "        self.unknown = _coerce_to_list(unknown)\n",
    "        self.static = _coerce_to_list(static)\n",
    "\n",
    "        self.feature_cols = [\n",
    "            col\n",
    "            for col in data.columns\n",
    "            if col not in [self.time] + self.group + [self.weight] + self.target\n",
    "        ]\n",
    "        if self.group:\n",
    "            self._groups = self.data.groupby(self.group).groups\n",
    "            self._group_ids = list(self._groups.keys())\n",
    "        else:\n",
    "            self._groups = {\"_single_group\": self.data.index}\n",
    "            self._group_ids = [\"_single_group\"]\n",
    "\n",
    "        self._prepare_metadata()\n",
    "\n",
    "    def _prepare_metadata(self):\n",
    "        \"\"\"Prepare metadata for the dataset.\n",
    "\n",
    "        The funcion returns metadata that contains:\n",
    "\n",
    "        * ``cols``: dict { 'y': list[str], 'x': list[str], 'st': list[str] }\n",
    "          Names of columns for y, x, and static features.\n",
    "          List elements are in same order as column dimensions.\n",
    "          Columns not appearing are assumed to be named (x0, x1, etc.),\n",
    "          (y0, y1, etc.), (st0, st1, etc.).\n",
    "        * ``col_type``: dict[str, str]\n",
    "          maps column names to data types \"F\" (numerical) and \"C\" (categorical).\n",
    "          Column names not occurring are assumed \"F\".\n",
    "        * ``col_known``: dict[str, str]\n",
    "          maps column names to \"K\" (future known) or \"U\" (future unknown).\n",
    "          Column names not occurring are assumed \"K\".\n",
    "        \"\"\"\n",
    "        self.metadata = {\n",
    "            \"cols\": {\n",
    "                \"y\": self.target,\n",
    "                \"x\": self.feature_cols,\n",
    "                \"st\": self.static,\n",
    "            },\n",
    "            \"col_type\": {},\n",
    "            \"col_known\": {},\n",
    "        }\n",
    "\n",
    "        all_cols = self.target + self.feature_cols + self.static\n",
    "        for col in all_cols:\n",
    "            self.metadata[\"col_type\"][col] = \"C\" if col in self.cat else \"F\"\n",
    "\n",
    "            self.metadata[\"col_known\"][col] = \"K\" if col in self.known else \"U\"\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return number of time series in the dataset.\"\"\"\n",
    "        return len(self._group_ids)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Get time series data for given index.\n",
    "\n",
    "        It returns:\n",
    "\n",
    "        * ``t``: ``numpy.ndarray`` of shape (n_timepoints,)\n",
    "          Time index for each time point in the past or present. Aligned with ``y``,\n",
    "          and ``x`` not ending in ``f``.\n",
    "        * ``y``: tensor of shape (n_timepoints, n_targets)\n",
    "          Target values for each time point. Rows are time points, aligned with ``t``.\n",
    "        * ``x``: tensor of shape (n_timepoints, n_features)\n",
    "          Features for each time point. Rows are time points, aligned with ``t``.\n",
    "        * ``group``: tensor of shape (n_groups)\n",
    "          Group identifiers for time series instances.\n",
    "        * ``st``: tensor of shape (n_static_features)\n",
    "          Static features.\n",
    "        * ``cutoff_time``: float or ``numpy.float64``\n",
    "          Cutoff time for the time series instance.\n",
    "\n",
    "        Optionally, the following str-keyed entry can be included:\n",
    "\n",
    "        * ``weights``: tensor of shape (n_timepoints), only if weight is not None\n",
    "        \"\"\"\n",
    "        group_id = self._group_ids[index]\n",
    "\n",
    "        if self.group:\n",
    "            mask = self._groups[group_id]\n",
    "            data = self.data.loc[mask]\n",
    "        else:\n",
    "            data = self.data\n",
    "\n",
    "        cutoff_time = data[self.time].max()\n",
    "\n",
    "        result = {\n",
    "            \"t\": data[self.time].values,\n",
    "            \"y\": torch.tensor(data[self.target].values),\n",
    "            \"x\": torch.tensor(data[self.feature_cols].values),\n",
    "            \"group\": torch.tensor([hash(str(group_id))]),\n",
    "            \"st\": torch.tensor(data[self.static].iloc[0].values if self.static else []),\n",
    "            \"cutoff_time\": cutoff_time,\n",
    "        }\n",
    "\n",
    "        if self.data_future is not None:\n",
    "            if self.group:\n",
    "                future_mask = self.data_future.groupby(self.group).groups[group_id]\n",
    "                future_data = self.data_future.loc[future_mask]\n",
    "            else:\n",
    "                future_data = self.data_future\n",
    "\n",
    "            combined_times = np.concatenate(\n",
    "                [data[self.time].values, future_data[self.time].values]\n",
    "            )\n",
    "            combined_times = np.unique(combined_times)\n",
    "            combined_times.sort()\n",
    "\n",
    "            num_timepoints = len(combined_times)\n",
    "            x_merged = np.full((num_timepoints, len(self.feature_cols)), np.nan)\n",
    "            y_merged = np.full((num_timepoints, len(self.target)), np.nan)\n",
    "\n",
    "            current_time_indices = {t: i for i, t in enumerate(combined_times)}\n",
    "            for i, t in enumerate(data[self.time].values):\n",
    "                idx = current_time_indices[t]\n",
    "                x_merged[idx] = data[self.feature_cols].values[i]\n",
    "                y_merged[idx] = data[self.target].values[i]\n",
    "\n",
    "            for i, t in enumerate(future_data[self.time].values):\n",
    "                if t in current_time_indices:\n",
    "                    idx = current_time_indices[t]\n",
    "                    for j, col in enumerate(self.known):\n",
    "                        if col in self.feature_cols:\n",
    "                            feature_idx = self.feature_cols.index(col)\n",
    "                            x_merged[idx, feature_idx] = future_data[col].values[i]\n",
    "\n",
    "            result.update(\n",
    "                {\n",
    "                    \"t\": combined_times,\n",
    "                    \"x\": torch.tensor(x_merged, dtype=torch.float32),\n",
    "                    \"y\": torch.tensor(y_merged, dtype=torch.float32),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if self.weight:\n",
    "            if self.data_future is not None and self.weight in self.data_future.columns:\n",
    "                weights_merged = np.full(num_timepoints, np.nan)\n",
    "                for i, t in enumerate(data[self.time].values):\n",
    "                    idx = current_time_indices[t]\n",
    "                    weights_merged[idx] = data[self.weight].values[i]\n",
    "\n",
    "                for i, t in enumerate(future_data[self.time].values):\n",
    "                    if t in current_time_indices and self.weight in future_data.columns:\n",
    "                        idx = current_time_indices[t]\n",
    "                        weights_merged[idx] = future_data[self.weight].values[i]\n",
    "\n",
    "                result[\"weights\"] = torch.tensor(weights_merged, dtype=torch.float32)\n",
    "            else:\n",
    "                result[\"weights\"] = torch.tensor(\n",
    "                    data[self.weight].values, dtype=torch.float32\n",
    "                )\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_metadata(self) -> Dict:\n",
    "        \"\"\"Return metadata about the dataset.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict\n",
    "            Dictionary containing:\n",
    "            - cols: column names for y, x, and static features\n",
    "            - col_type: mapping of columns to their types (F/C)\n",
    "            - col_known: mapping of columns to their future known status (K/U)\n",
    "        \"\"\"\n",
    "        return self.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "0Rw9LgsXJI5V"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "from lightning.pytorch import LightningDataModule\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from pytorch_forecasting.data.encoders import (\n",
    "    EncoderNormalizer,\n",
    "    NaNLabelEncoder,\n",
    "    TorchNormalizer,\n",
    ")\n",
    "\n",
    "NORMALIZER = Union[TorchNormalizer, NaNLabelEncoder, EncoderNormalizer]\n",
    "\n",
    "\n",
    "class EncoderDecoderTimeSeriesDataModule(LightningDataModule):\n",
    "    \"\"\"\n",
    "    Lightning DataModule for processing time series data in an encoder-decoder format.\n",
    "\n",
    "    This module handles preprocessing, splitting, and batching of time series data\n",
    "    for use in deep learning models. It supports categorical and continuous features,\n",
    "    various scalers, and automatic target normalization.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time_series_dataset : TimeSeries\n",
    "        The dataset containing time series data.\n",
    "    max_encoder_length : int, default=30\n",
    "        Maximum length of the encoder input sequence.\n",
    "    min_encoder_length : Optional[int], default=None\n",
    "        Minimum length of the encoder input sequence.\n",
    "        Defaults to `max_encoder_length` if not specified.\n",
    "    max_prediction_length : int, default=1\n",
    "        Maximum length of the decoder output sequence.\n",
    "    min_prediction_length : Optional[int], default=None\n",
    "        Minimum length of the decoder output sequence.\n",
    "        Defaults to `max_prediction_length` if not specified.\n",
    "    min_prediction_idx : Optional[int], default=None\n",
    "        Minimum index from which predictions start.\n",
    "    allow_missing_timesteps : bool, default=False\n",
    "        Whether to allow missing timesteps in the dataset.\n",
    "    add_relative_time_idx : bool, default=False\n",
    "        Whether to add a relative time index feature.\n",
    "    add_target_scales : bool, default=False\n",
    "        Whether to add target scaling information.\n",
    "    add_encoder_length : Union[bool, str], default=\"auto\"\n",
    "        Whether to include encoder length information.\n",
    "    target_normalizer :\n",
    "        Union[NORMALIZER, str, List[NORMALIZER], Tuple[NORMALIZER], None],\n",
    "         default=\"auto\"\n",
    "        Normalizer for the target variable. If \"auto\", uses `RobustScaler`.\n",
    "\n",
    "    categorical_encoders : Optional[Dict[str, NaNLabelEncoder]], default=None\n",
    "        Dictionary of categorical encoders.\n",
    "\n",
    "    scalers :\n",
    "    Optional[Dict[str, Union[StandardScaler, RobustScaler,\n",
    "                        TorchNormalizer, EncoderNormalizer]]], default=None\n",
    "        Dictionary of feature scalers.\n",
    "\n",
    "    randomize_length : Union[None, Tuple[float, float], bool], default=False\n",
    "        Whether to randomize input sequence length.\n",
    "    batch_size : int, default=32\n",
    "        Batch size for DataLoader.\n",
    "    num_workers : int, default=0\n",
    "        Number of workers for DataLoader.\n",
    "    train_val_test_split : tuple, default=(0.7, 0.15, 0.15)\n",
    "        Proportions for train, validation, and test dataset splits.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        time_series_dataset: TimeSeries,\n",
    "        max_encoder_length: int = 30,\n",
    "        min_encoder_length: Optional[int] = None,\n",
    "        max_prediction_length: int = 1,\n",
    "        min_prediction_length: Optional[int] = None,\n",
    "        min_prediction_idx: Optional[int] = None,\n",
    "        allow_missing_timesteps: bool = False,\n",
    "        add_relative_time_idx: bool = False,\n",
    "        add_target_scales: bool = False,\n",
    "        add_encoder_length: Union[bool, str] = \"auto\",\n",
    "        target_normalizer: Union[\n",
    "            NORMALIZER, str, List[NORMALIZER], Tuple[NORMALIZER], None\n",
    "        ] = \"auto\",\n",
    "        categorical_encoders: Optional[Dict[str, NaNLabelEncoder]] = None,\n",
    "        scalers: Optional[\n",
    "            Dict[\n",
    "                str,\n",
    "                Union[StandardScaler, RobustScaler, TorchNormalizer, EncoderNormalizer],\n",
    "            ]\n",
    "        ] = None,\n",
    "        randomize_length: Union[None, Tuple[float, float], bool] = False,\n",
    "        batch_size: int = 32,\n",
    "        num_workers: int = 0,\n",
    "        train_val_test_split: tuple = (0.7, 0.15, 0.15),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.time_series_dataset = time_series_dataset\n",
    "        self.time_series_metadata = time_series_dataset.get_metadata()\n",
    "\n",
    "        self.max_encoder_length = max_encoder_length\n",
    "        self.min_encoder_length = min_encoder_length or max_encoder_length\n",
    "        self.max_prediction_length = max_prediction_length\n",
    "        self.min_prediction_length = min_prediction_length or max_prediction_length\n",
    "        self.min_prediction_idx = min_prediction_idx\n",
    "\n",
    "        self.allow_missing_timesteps = allow_missing_timesteps\n",
    "        self.add_relative_time_idx = add_relative_time_idx\n",
    "        self.add_target_scales = add_target_scales\n",
    "        self.add_encoder_length = add_encoder_length\n",
    "        self.randomize_length = randomize_length\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.train_val_test_split = train_val_test_split\n",
    "\n",
    "        if isinstance(target_normalizer, str) and target_normalizer.lower() == \"auto\":\n",
    "            self.target_normalizer = RobustScaler()\n",
    "        else:\n",
    "            self.target_normalizer = target_normalizer\n",
    "\n",
    "        self.categorical_encoders = _coerce_to_dict(categorical_encoders)\n",
    "        self.scalers = _coerce_to_dict(scalers)\n",
    "\n",
    "        self.categorical_indices = []\n",
    "        self.continuous_indices = []\n",
    "        self._metadata = None\n",
    "\n",
    "        for idx, col in enumerate(self.time_series_metadata[\"cols\"][\"x\"]):\n",
    "            if self.time_series_metadata[\"col_type\"].get(col) == \"C\":\n",
    "                self.categorical_indices.append(idx)\n",
    "            else:\n",
    "                self.continuous_indices.append(idx)\n",
    "\n",
    "    def _prepare_metadata(self):\n",
    "        \"\"\"Prepare metadata for model initialisation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            dictionary containing the following keys:\n",
    "\n",
    "                * ``encoder_cat``: Number of categorical variables in the encoder.\n",
    "                    Computed as ``len(self.categorical_indices)``, which counts the\n",
    "                    categorical feature indices.\n",
    "                * ``encoder_cont``: Number of continuous variables in the encoder.\n",
    "                    Computed as ``len(self.continuous_indices)``, which counts the\n",
    "                    continuous feature indices.\n",
    "                * ``decoder_cat``: Number of categorical variables in the decoder that\n",
    "                    are known in advance.\n",
    "                    Computed by filtering ``self.time_series_metadata[\"cols\"][\"x\"]``\n",
    "                    where col_type == \"C\"(categorical) and col_known == \"K\" (known)\n",
    "                * ``decoder_cont``:  Number of continuous variables in the decoder that\n",
    "                    are known in advance.\n",
    "                    Computed by filtering ``self.time_series_metadata[\"cols\"][\"x\"]``\n",
    "                    where col_type == \"F\"(continuous) and col_known == \"K\"(known)\n",
    "                * ``target``: Number of target variables.\n",
    "                    Computed as ``len(self.time_series_metadata[\"cols\"][\"y\"])``, which\n",
    "                    gives the number of output target columns..\n",
    "                * ``static_categorical_features``: Number of static categorical features\n",
    "                    Computed by filtering ``self.time_series_metadata[\"cols\"][\"st\"]``\n",
    "                    (static features) where col_type == \"C\" (categorical).\n",
    "                * ``static_continuous_features``: Number of static continuous features\n",
    "                    Computed as difference of\n",
    "                    ``len(self.time_series_metadata[\"cols\"][\"st\"])`` (static features)\n",
    "                    and static_categorical_features that gives static continuous feature\n",
    "                * ``max_encoder_length``: maximum encoder length\n",
    "                    Taken directly from `self.max_encoder_length`.\n",
    "                * ``max_prediction_length``: maximum prediction length\n",
    "                    Taken directly from `self.max_prediction_length`.\n",
    "                * ``min_encoder_length``: minimum encoder length\n",
    "                    Taken directly from `self.min_encoder_length`.\n",
    "                * ``min_prediction_length``: minimum prediction length\n",
    "                    Taken directly from `self.min_prediction_length`.\n",
    "\n",
    "        \"\"\"\n",
    "        encoder_cat_count = len(self.categorical_indices)\n",
    "        encoder_cont_count = len(self.continuous_indices)\n",
    "\n",
    "        decoder_cat_count = len(\n",
    "            [\n",
    "                col\n",
    "                for col in self.time_series_metadata[\"cols\"][\"x\"]\n",
    "                if self.time_series_metadata[\"col_type\"].get(col) == \"C\"\n",
    "                and self.time_series_metadata[\"col_known\"].get(col) == \"K\"\n",
    "            ]\n",
    "        )\n",
    "        decoder_cont_count = len(\n",
    "            [\n",
    "                col\n",
    "                for col in self.time_series_metadata[\"cols\"][\"x\"]\n",
    "                if self.time_series_metadata[\"col_type\"].get(col) == \"F\"\n",
    "                and self.time_series_metadata[\"col_known\"].get(col) == \"K\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        target_count = len(self.time_series_metadata[\"cols\"][\"y\"])\n",
    "        metadata = {\n",
    "            \"encoder_cat\": encoder_cat_count,\n",
    "            \"encoder_cont\": encoder_cont_count,\n",
    "            \"decoder_cat\": decoder_cat_count,\n",
    "            \"decoder_cont\": decoder_cont_count,\n",
    "            \"target\": target_count,\n",
    "        }\n",
    "        if self.time_series_metadata[\"cols\"][\"st\"]:\n",
    "            static_cat_count = len(\n",
    "                [\n",
    "                    col\n",
    "                    for col in self.time_series_metadata[\"cols\"][\"st\"]\n",
    "                    if self.time_series_metadata[\"col_type\"].get(col) == \"C\"\n",
    "                ]\n",
    "            )\n",
    "            static_cont_count = (\n",
    "                len(self.time_series_metadata[\"cols\"][\"st\"]) - static_cat_count\n",
    "            )\n",
    "\n",
    "            metadata[\"static_categorical_features\"] = static_cat_count\n",
    "            metadata[\"static_continuous_features\"] = static_cont_count\n",
    "        else:\n",
    "            metadata[\"static_categorical_features\"] = 0\n",
    "            metadata[\"static_continuous_features\"] = 0\n",
    "\n",
    "        metadata.update(\n",
    "            {\n",
    "                \"max_encoder_length\": self.max_encoder_length,\n",
    "                \"max_prediction_length\": self.max_prediction_length,\n",
    "                \"min_encoder_length\": self.min_encoder_length,\n",
    "                \"min_prediction_length\": self.min_prediction_length,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return metadata\n",
    "\n",
    "    @property\n",
    "    def metadata(self):\n",
    "        \"\"\"Compute metadata for model initialization.\n",
    "\n",
    "        This property returns a dictionary containing the shapes and key information\n",
    "        related to the time series model. The metadata includes:\n",
    "\n",
    "        * ``encoder_cat``: Number of categorical variables in the encoder.\n",
    "        * ``encoder_cont``: Number of continuous variables in the encoder.\n",
    "        * ``decoder_cat``: Number of categorical variables in the decoder that are\n",
    "                            known in advance.\n",
    "        * ``decoder_cont``:  Number of continuous variables in the decoder that are\n",
    "                            known in advance.\n",
    "        * ``target``: Number of target variables.\n",
    "\n",
    "        If static features are present, the following keys are added:\n",
    "\n",
    "        * ``static_categorical_features``: Number of static categorical features\n",
    "        * ``static_continuous_features``: Number of static continuous features\n",
    "\n",
    "        It also contains the following information:\n",
    "\n",
    "        * ``max_encoder_length``: maximum encoder length\n",
    "        * ``max_prediction_length``: maximum prediction length\n",
    "        * ``min_encoder_length``: minimum encoder length\n",
    "        * ``min_prediction_length``: minimum prediction length\n",
    "        \"\"\"\n",
    "        if self._metadata is None:\n",
    "            self._metadata = self._prepare_metadata()\n",
    "        return self._metadata\n",
    "\n",
    "    def _preprocess_data(self, indices: torch.Tensor) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Preprocess the data before feeding it into _ProcessedEncoderDecoderDataset.\n",
    "\n",
    "        Preprocessing steps\n",
    "        --------------------\n",
    "\n",
    "        * Converts target (`y`) and features (`x`) to `torch.float32`.\n",
    "        * Masks time points that are at or before the cutoff time.\n",
    "        * Splits features into categorical and continuous subsets based on\n",
    "            predefined indices.\n",
    "\n",
    "\n",
    "        TODO: add scalers, target normalizers etc.\n",
    "        \"\"\"\n",
    "        processed_data = []\n",
    "\n",
    "        for idx in indices:\n",
    "            sample = self.time_series_dataset[idx.item()]\n",
    "\n",
    "            target = sample[\"y\"]\n",
    "            features = sample[\"x\"]\n",
    "            times = sample[\"t\"]\n",
    "            cutoff_time = sample[\"cutoff_time\"]\n",
    "\n",
    "            time_mask = torch.tensor(times <= cutoff_time, dtype=torch.bool)\n",
    "\n",
    "            if isinstance(target, torch.Tensor):\n",
    "                target = target.float()\n",
    "            else:\n",
    "                target = torch.tensor(target, dtype=torch.float32)\n",
    "\n",
    "            if isinstance(features, torch.Tensor):\n",
    "                features = features.float()\n",
    "            else:\n",
    "                features = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "            # TODO: add scalers, target normalizers etc.\n",
    "\n",
    "            categorical = (\n",
    "                features[:, self.categorical_indices]\n",
    "                if self.categorical_indices\n",
    "                else torch.zeros((features.shape[0], 0))\n",
    "            )\n",
    "            continuous = (\n",
    "                features[:, self.continuous_indices]\n",
    "                if self.continuous_indices\n",
    "                else torch.zeros((features.shape[0], 0))\n",
    "            )\n",
    "\n",
    "            processed_data.append(\n",
    "                {\n",
    "                    \"features\": {\"categorical\": categorical, \"continuous\": continuous},\n",
    "                    \"target\": target,\n",
    "                    \"static\": sample.get(\"st\", None),\n",
    "                    \"group\": sample.get(\"group\", torch.tensor([0])),\n",
    "                    \"length\": len(target),\n",
    "                    \"time_mask\": time_mask,\n",
    "                    \"times\": times,\n",
    "                    \"cutoff_time\": cutoff_time,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return processed_data\n",
    "\n",
    "    class _ProcessedEncoderDecoderDataset(Dataset):\n",
    "        \"\"\"PyTorch Dataset for processed encoder-decoder time series data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        processed_data : List[Dict[str, Any]]\n",
    "            List of preprocessed time series samples.\n",
    "        windows : List[Tuple[int, int, int, int]]\n",
    "            List of window tuples containing\n",
    "            (series_idx, start_idx, enc_length, pred_length).\n",
    "        add_relative_time_idx : bool, default=False\n",
    "            Whether to include relative time indices.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(\n",
    "            self,\n",
    "            processed_data: List[Dict[str, Any]],\n",
    "            windows: List[Tuple[int, int, int, int]],\n",
    "            add_relative_time_idx: bool = False,\n",
    "        ):\n",
    "            self.processed_data = processed_data\n",
    "            self.windows = windows\n",
    "            self.add_relative_time_idx = add_relative_time_idx\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.windows)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            \"\"\"Retrieve a processed time series window for dataloader input.\n",
    "\n",
    "            x : dict\n",
    "                Dictionary containing model inputs:\n",
    "\n",
    "                * ``encoder_cat`` : tensor of shape (enc_length, n_cat_features)\n",
    "                  Categorical features for the encoder.\n",
    "                * ``encoder_cont`` : tensor of shape (enc_length, n_cont_features)\n",
    "                  Continuous features for the encoder.\n",
    "                * ``decoder_cat`` : tensor of shape (pred_length, n_cat_features)\n",
    "                  Categorical features for the decoder.\n",
    "                * ``decoder_cont`` : tensor of shape (pred_length, n_cont_features)\n",
    "                  Continuous features for the decoder.\n",
    "                * ``encoder_lengths`` : tensor of shape (1,)\n",
    "                  Length of the encoder sequence.\n",
    "                * ``decoder_lengths`` : tensor of shape (1,)\n",
    "                  Length of the decoder sequence.\n",
    "                * ``decoder_target_lengths`` : tensor of shape (1,)\n",
    "                  Length of the decoder target sequence.\n",
    "                * ``groups`` : tensor of shape (1,)\n",
    "                  Group identifier for the time series instance.\n",
    "                * ``encoder_time_idx`` : tensor of shape (enc_length,)\n",
    "                  Time indices for the encoder sequence.\n",
    "                * ``decoder_time_idx`` : tensor of shape (pred_length,)\n",
    "                  Time indices for the decoder sequence.\n",
    "                * ``target_scale`` : tensor of shape (1,)\n",
    "                  Scaling factor for the target values.\n",
    "                * ``encoder_mask`` : tensor of shape (enc_length,)\n",
    "                  Boolean mask indicating valid encoder time points.\n",
    "                * ``decoder_mask`` : tensor of shape (pred_length,)\n",
    "                  Boolean mask indicating valid decoder time points.\n",
    "\n",
    "                  If static features are present, the following keys are added:\n",
    "\n",
    "                * ``static_categorical_features`` : tensor of shape\n",
    "                                                    (1, n_static_cat_features), optional\n",
    "                  Static categorical features, if available.\n",
    "                * ``static_continuous_features`` : tensor of shape (1, 0), optional\n",
    "                  Placeholder for static continuous features (currently empty).\n",
    "\n",
    "            y : tensor of shape ``(pred_length, n_targets)``\n",
    "                Target values for the decoder sequence.\n",
    "            \"\"\"\n",
    "            series_idx, start_idx, enc_length, pred_length = self.windows[idx]\n",
    "            data = self.processed_data[series_idx]\n",
    "\n",
    "            end_idx = start_idx + enc_length + pred_length\n",
    "            encoder_indices = slice(start_idx, start_idx + enc_length)\n",
    "            decoder_indices = slice(start_idx + enc_length, end_idx)\n",
    "\n",
    "            target_scale = data[\"target\"][encoder_indices]\n",
    "            target_scale = target_scale[~torch.isnan(target_scale)].abs().mean()\n",
    "            if torch.isnan(target_scale) or target_scale == 0:\n",
    "                target_scale = torch.tensor(1.0)\n",
    "\n",
    "            encoder_mask = (\n",
    "                data[\"time_mask\"][encoder_indices]\n",
    "                if \"time_mask\" in data\n",
    "                else torch.ones(enc_length, dtype=torch.bool)\n",
    "            )\n",
    "            decoder_mask = (\n",
    "                data[\"time_mask\"][decoder_indices]\n",
    "                if \"time_mask\" in data\n",
    "                else torch.zeros(pred_length, dtype=torch.bool)\n",
    "            )\n",
    "\n",
    "            x = {\n",
    "                \"encoder_cat\": data[\"features\"][\"categorical\"][encoder_indices],\n",
    "                \"encoder_cont\": data[\"features\"][\"continuous\"][encoder_indices],\n",
    "                \"decoder_cat\": data[\"features\"][\"categorical\"][decoder_indices],\n",
    "                \"decoder_cont\": data[\"features\"][\"continuous\"][decoder_indices],\n",
    "                \"encoder_lengths\": torch.tensor(enc_length),\n",
    "                \"decoder_lengths\": torch.tensor(pred_length),\n",
    "                \"decoder_target_lengths\": torch.tensor(pred_length),\n",
    "                \"groups\": data[\"group\"],\n",
    "                \"encoder_time_idx\": torch.arange(enc_length),\n",
    "                \"decoder_time_idx\": torch.arange(enc_length, enc_length + pred_length),\n",
    "                \"target_scale\": target_scale,\n",
    "                \"encoder_mask\": encoder_mask,\n",
    "                \"decoder_mask\": decoder_mask,\n",
    "            }\n",
    "            if data[\"static\"] is not None:\n",
    "                x[\"static_categorical_features\"] = data[\"static\"].unsqueeze(0)\n",
    "                x[\"static_continuous_features\"] = torch.zeros((1, 0))\n",
    "\n",
    "            y = data[\"target\"][decoder_indices]\n",
    "            if y.ndim == 1:\n",
    "                y = y.unsqueeze(-1)\n",
    "\n",
    "            return x, y\n",
    "\n",
    "    def _create_windows(\n",
    "        self, processed_data: List[Dict[str, Any]]\n",
    "    ) -> List[Tuple[int, int, int, int]]:\n",
    "        \"\"\"Generate sliding windows for training, validation, and testing.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List[Tuple[int, int, int, int]]\n",
    "            A list of tuples, where each tuple consists of:\n",
    "            - ``series_idx`` : int\n",
    "              Index of the time series in `processed_data`.\n",
    "            - ``start_idx`` : int\n",
    "              Start index of the encoder window.\n",
    "            - ``enc_length`` : int\n",
    "              Length of the encoder input sequence.\n",
    "            - ``pred_length`` : int\n",
    "              Length of the decoder output sequence.\n",
    "        \"\"\"\n",
    "        windows = []\n",
    "\n",
    "        for idx, data in enumerate(processed_data):\n",
    "            sequence_length = data[\"length\"]\n",
    "\n",
    "            if sequence_length < self.max_encoder_length + self.max_prediction_length:\n",
    "                continue\n",
    "\n",
    "            effective_min_prediction_idx = (\n",
    "                self.min_prediction_idx\n",
    "                if self.min_prediction_idx is not None\n",
    "                else self.max_encoder_length\n",
    "            )\n",
    "\n",
    "            max_prediction_idx = sequence_length - self.max_prediction_length + 1\n",
    "\n",
    "            if max_prediction_idx <= effective_min_prediction_idx:\n",
    "                continue\n",
    "\n",
    "            for start_idx in range(\n",
    "                0, max_prediction_idx - effective_min_prediction_idx\n",
    "            ):\n",
    "                if (\n",
    "                    start_idx + self.max_encoder_length + self.max_prediction_length\n",
    "                    <= sequence_length\n",
    "                ):\n",
    "                    windows.append(\n",
    "                        (\n",
    "                            idx,\n",
    "                            start_idx,\n",
    "                            self.max_encoder_length,\n",
    "                            self.max_prediction_length,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "        return windows\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        \"\"\"Prepare the datasets for training, validation, testing, or prediction.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stage : Optional[str], default=None\n",
    "            Specifies the stage of setup. Can be one of:\n",
    "            - ``\"fit\"`` : Prepares training and validation datasets.\n",
    "            - ``\"test\"`` : Prepares the test dataset.\n",
    "            - ``\"predict\"`` : Prepares the dataset for inference.\n",
    "            - ``None`` : Prepares all datasets.\n",
    "        \"\"\"\n",
    "        total_series = len(self.time_series_dataset)\n",
    "        self._split_indices = torch.randperm(total_series)\n",
    "\n",
    "        self._train_size = int(self.train_val_test_split[0] * total_series)\n",
    "        self._val_size = int(self.train_val_test_split[1] * total_series)\n",
    "\n",
    "        self._train_indices = self._split_indices[: self._train_size]\n",
    "        self._val_indices = self._split_indices[\n",
    "            self._train_size : self._train_size + self._val_size\n",
    "        ]\n",
    "        self._test_indices = self._split_indices[self._train_size + self._val_size :]\n",
    "\n",
    "        if stage is None or stage == \"fit\":\n",
    "            if not hasattr(self, \"train_dataset\") or not hasattr(self, \"val_dataset\"):\n",
    "                self.train_processed = self._preprocess_data(self._train_indices)\n",
    "                self.val_processed = self._preprocess_data(self._val_indices)\n",
    "\n",
    "                self.train_windows = self._create_windows(self.train_processed)\n",
    "                self.val_windows = self._create_windows(self.val_processed)\n",
    "\n",
    "                self.train_dataset = self._ProcessedEncoderDecoderDataset(\n",
    "                    self.train_processed, self.train_windows, self.add_relative_time_idx\n",
    "                )\n",
    "                self.val_dataset = self._ProcessedEncoderDecoderDataset(\n",
    "                    self.val_processed, self.val_windows, self.add_relative_time_idx\n",
    "                )\n",
    "                # print(self.val_dataset[0])\n",
    "\n",
    "        elif stage is None or stage == \"test\":\n",
    "            if not hasattr(self, \"test_dataset\"):\n",
    "                self.test_processed = self._preprocess_data(self._test_indices)\n",
    "                self.test_windows = self._create_windows(self.test_processed)\n",
    "\n",
    "                self.test_dataset = self._ProcessedEncoderDecoderDataset(\n",
    "                    self.test_processed, self.test_windows, self.add_relative_time_idx\n",
    "                )\n",
    "        elif stage == \"predict\":\n",
    "            predict_indices = torch.arange(len(self.time_series_dataset))\n",
    "            self.predict_processed = self._preprocess_data(predict_indices)\n",
    "            self.predict_windows = self._create_windows(self.predict_processed)\n",
    "            self.predict_dataset = self._ProcessedEncoderDecoderDataset(\n",
    "                self.predict_processed, self.predict_windows, self.add_relative_time_idx\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "            collate_fn=self.collate_fn,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=self.collate_fn,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=self.collate_fn,\n",
    "        )\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.predict_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=self.collate_fn,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        x_batch = {\n",
    "            \"encoder_cat\": torch.stack([x[\"encoder_cat\"] for x, _ in batch]),\n",
    "            \"encoder_cont\": torch.stack([x[\"encoder_cont\"] for x, _ in batch]),\n",
    "            \"decoder_cat\": torch.stack([x[\"decoder_cat\"] for x, _ in batch]),\n",
    "            \"decoder_cont\": torch.stack([x[\"decoder_cont\"] for x, _ in batch]),\n",
    "            \"encoder_lengths\": torch.stack([x[\"encoder_lengths\"] for x, _ in batch]),\n",
    "            \"decoder_lengths\": torch.stack([x[\"decoder_lengths\"] for x, _ in batch]),\n",
    "            \"decoder_target_lengths\": torch.stack(\n",
    "                [x[\"decoder_target_lengths\"] for x, _ in batch]\n",
    "            ),\n",
    "            \"groups\": torch.stack([x[\"groups\"] for x, _ in batch]),\n",
    "            \"encoder_time_idx\": torch.stack([x[\"encoder_time_idx\"] for x, _ in batch]),\n",
    "            \"decoder_time_idx\": torch.stack([x[\"decoder_time_idx\"] for x, _ in batch]),\n",
    "            \"target_scale\": torch.stack([x[\"target_scale\"] for x, _ in batch]),\n",
    "            \"encoder_mask\": torch.stack([x[\"encoder_mask\"] for x, _ in batch]),\n",
    "            \"decoder_mask\": torch.stack([x[\"decoder_mask\"] for x, _ in batch]),\n",
    "        }\n",
    "\n",
    "        if \"static_categorical_features\" in batch[0][0]:\n",
    "            x_batch[\"static_categorical_features\"] = torch.stack(\n",
    "                [x[\"static_categorical_features\"] for x, _ in batch]\n",
    "            )\n",
    "            x_batch[\"static_continuous_features\"] = torch.stack(\n",
    "                [x[\"static_continuous_features\"] for x, _ in batch]\n",
    "            )\n",
    "\n",
    "        y_batch = torch.stack([y for _, y in batch])\n",
    "        return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "WX-FRdusJSVN",
    "outputId": "730f0fe2-f5af-4871-859d-9a4043bbeac7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"data_df\",\n  \"rows\": 4900,\n  \"fields\": [\n    {\n      \"column\": \"series_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          83,\n          53,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 0,\n        \"max\": 48,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          13,\n          45,\n          47\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6723608094711289,\n        \"min\": -1.2295384314749236,\n        \"max\": 1.3194322331654313,\n        \"num_unique_values\": 4900,\n        \"samples\": [\n          0.3958947786657995,\n          0.7816648993958805,\n          -0.9655256111265276\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6766981377008536,\n        \"min\": -1.2295384314749236,\n        \"max\": 1.3194322331654313,\n        \"num_unique_values\": 4900,\n        \"samples\": [\n          0.5707668517530808,\n          0.5020485177883972,\n          -0.7734543579445009\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"future_known_feature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6741140972121411,\n        \"min\": -0.9991351502732795,\n        \"max\": 1.0,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          0.26749882862458735,\n          -0.2107957994307797,\n          -0.01238866346289056\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"static_feature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2783997753182645,\n        \"min\": 0.011560494046953695,\n        \"max\": 0.9996855497257285,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.43066463390546217,\n          0.08751257529405387,\n          0.3593350820130162\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"static_feature_cat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "data_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-dec0f8d8-ce59-4b24-823f-ac1394cf3756\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>category</th>\n",
       "      <th>future_known_feature</th>\n",
       "      <th>static_feature</th>\n",
       "      <th>static_feature_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023138</td>\n",
       "      <td>0.249834</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.249834</td>\n",
       "      <td>0.213821</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995004</td>\n",
       "      <td>0.454668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.213821</td>\n",
       "      <td>0.671829</td>\n",
       "      <td>0</td>\n",
       "      <td>0.980067</td>\n",
       "      <td>0.454668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.671829</td>\n",
       "      <td>0.781042</td>\n",
       "      <td>0</td>\n",
       "      <td>0.955336</td>\n",
       "      <td>0.454668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.781042</td>\n",
       "      <td>0.706092</td>\n",
       "      <td>0</td>\n",
       "      <td>0.921061</td>\n",
       "      <td>0.454668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dec0f8d8-ce59-4b24-823f-ac1394cf3756')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-dec0f8d8-ce59-4b24-823f-ac1394cf3756 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-dec0f8d8-ce59-4b24-823f-ac1394cf3756');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-a6f440ee-9920-47b1-8275-848606b5f779\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a6f440ee-9920-47b1-8275-848606b5f779')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-a6f440ee-9920-47b1-8275-848606b5f779 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   series_id  time_idx         x         y  category  future_known_feature  \\\n",
       "0          0         0  0.023138  0.249834         0              1.000000   \n",
       "1          0         1  0.249834  0.213821         0              0.995004   \n",
       "2          0         2  0.213821  0.671829         0              0.980067   \n",
       "3          0         3  0.671829  0.781042         0              0.955336   \n",
       "4          0         4  0.781042  0.706092         0              0.921061   \n",
       "\n",
       "   static_feature  static_feature_cat  \n",
       "0        0.454668                   0  \n",
       "1        0.454668                   0  \n",
       "2        0.454668                   0  \n",
       "3        0.454668                   0  \n",
       "4        0.454668                   0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE\n",
    "\n",
    "num_series = 100\n",
    "seq_length = 50\n",
    "data_list = []\n",
    "for i in range(num_series):\n",
    "    x = np.arange(seq_length)\n",
    "    y = np.sin(x / 5.0) + np.random.normal(scale=0.1, size=seq_length)\n",
    "    category = i % 5\n",
    "    static_value = np.random.rand()\n",
    "    for t in range(seq_length - 1):\n",
    "        data_list.append(\n",
    "            {\n",
    "                \"series_id\": i,\n",
    "                \"time_idx\": t,\n",
    "                \"x\": y[t],\n",
    "                \"y\": y[t + 1],\n",
    "                \"category\": category,\n",
    "                \"future_known_feature\": np.cos(t / 10),\n",
    "                \"static_feature\": static_value,\n",
    "                \"static_feature_cat\": i % 3,\n",
    "            }\n",
    "        )\n",
    "data_df = pd.DataFrame(data_list)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "AxxPHK6AKSD2"
   },
   "outputs": [],
   "source": [
    "dataset = TimeSeries(\n",
    "    data=data_df,\n",
    "    time=\"time_idx\",\n",
    "    target=\"y\",\n",
    "    group=[\"series_id\"],\n",
    "    num=[\"x\", \"future_known_feature\", \"static_feature\"],\n",
    "    cat=[\"category\", \"static_feature_cat\"],\n",
    "    known=[\"future_known_feature\"],\n",
    "    unknown=[\"x\", \"category\"],\n",
    "    static=[\"static_feature\", \"static_feature_cat\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5U5Lr_ZFKX0s"
   },
   "outputs": [],
   "source": [
    "data_module = EncoderDecoderTimeSeriesDataModule(\n",
    "    time_series_dataset=dataset,\n",
    "    max_encoder_length=30,\n",
    "    max_prediction_length=1,\n",
    "    batch_size=32,\n",
    "    categorical_encoders={\n",
    "        \"category\": NaNLabelEncoder(add_nan=True),\n",
    "        \"static_feature_cat\": NaNLabelEncoder(add_nan=True),\n",
    "    },\n",
    "    scalers={\n",
    "        \"x\": StandardScaler(),\n",
    "        \"future_known_feature\": StandardScaler(),\n",
    "        \"static_feature\": StandardScaler(),\n",
    "    },\n",
    "    target_normalizer=TorchNormalizer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8NgHxNqK9uV"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "from lightning.pytorch import LightningModule\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT\n",
    "import torch\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "class BaseModel(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        loss: nn.Module,\n",
    "        logging_metrics: Optional[List[nn.Module]] = None,\n",
    "        optimizer: Optional[Union[Optimizer, str]] = \"adam\",\n",
    "        optimizer_params: Optional[Dict] = None,\n",
    "        lr_scheduler: Optional[str] = None,\n",
    "        lr_scheduler_params: Optional[Dict] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Base model for time series forecasting.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        loss : nn.Module\n",
    "            Loss function to use for training.\n",
    "        logging_metrics : Optional[List[nn.Module]], optional\n",
    "            List of metrics to log during training, validation, and testing.\n",
    "        optimizer : Optional[Union[Optimizer, str]], optional\n",
    "            Optimizer to use for training.\n",
    "            Can be a string (\"adam\", \"sgd\") or an instance of `torch.optim.Optimizer`.\n",
    "        optimizer_params : Optional[Dict], optional\n",
    "            Parameters for the optimizer.\n",
    "        lr_scheduler : Optional[str], optional\n",
    "            Learning rate scheduler to use.\n",
    "            Supported values: \"reduce_lr_on_plateau\", \"step_lr\".\n",
    "        lr_scheduler_params : Optional[Dict], optional\n",
    "            Parameters for the learning rate scheduler.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.loss = loss\n",
    "        self.logging_metrics = logging_metrics if logging_metrics is not None else []\n",
    "        self.optimizer = optimizer\n",
    "        self.optimizer_params = optimizer_params if optimizer_params is not None else {}\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.lr_scheduler_params = (\n",
    "            lr_scheduler_params if lr_scheduler_params is not None else {}\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : Dict[str, torch.Tensor]\n",
    "            Dictionary containing input tensors\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, torch.Tensor]\n",
    "            Dictionary containing output tensors\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Forward method must be implemented by subclass.\")\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: Tuple[Dict[str, torch.Tensor]], batch_idx: int\n",
    "    ) -> STEP_OUTPUT:\n",
    "        \"\"\"\n",
    "        Training step for the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : Tuple[Dict[str, torch.Tensor]]\n",
    "            Batch of data containing input and target tensors.\n",
    "        batch_idx : int\n",
    "            Index of the batch.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        STEP_OUTPUT\n",
    "            Dictionary containing the loss and other metrics.\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        y_hat_dict = self(x)\n",
    "        y_hat = y_hat_dict[\"prediction\"]\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        self.log_metrics(y_hat, y, prefix=\"train\")\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: Tuple[Dict[str, torch.Tensor]], batch_idx: int\n",
    "    ) -> STEP_OUTPUT:\n",
    "        \"\"\"\n",
    "        Validation step for the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : Tuple[Dict[str, torch.Tensor]]\n",
    "            Batch of data containing input and target tensors.\n",
    "        batch_idx : int\n",
    "            Index of the batch.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        STEP_OUTPUT\n",
    "            Dictionary containing the loss and other metrics.\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        y_hat_dict = self(x)\n",
    "        y_hat = y_hat_dict[\"prediction\"]\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log(\n",
    "            \"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        self.log_metrics(y_hat, y, prefix=\"val\")\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def test_step(\n",
    "        self, batch: Tuple[Dict[str, torch.Tensor]], batch_idx: int\n",
    "    ) -> STEP_OUTPUT:\n",
    "        \"\"\"\n",
    "        Test step for the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : Tuple[Dict[str, torch.Tensor]]\n",
    "            Batch of data containing input and target tensors.\n",
    "        batch_idx : int\n",
    "            Index of the batch.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        STEP_OUTPUT\n",
    "            Dictionary containing the loss and other metrics.\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        y_hat_dict = self(x)\n",
    "        y_hat = y_hat_dict[\"prediction\"]\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log(\n",
    "            \"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        self.log_metrics(y_hat, y, prefix=\"test\")\n",
    "        return {\"test_loss\": loss}\n",
    "\n",
    "    def predict_step(\n",
    "        self,\n",
    "        batch: Tuple[Dict[str, torch.Tensor]],\n",
    "        batch_idx: int,\n",
    "        dataloader_idx: int = 0,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Prediction step for the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : Tuple[Dict[str, torch.Tensor]]\n",
    "            Batch of data containing input tensors.\n",
    "        batch_idx : int\n",
    "            Index of the batch.\n",
    "        dataloader_idx : int\n",
    "            Index of the dataloader.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Predicted output tensor.\n",
    "        \"\"\"\n",
    "        x, _ = batch\n",
    "        y_hat = self(x)\n",
    "        return y_hat\n",
    "\n",
    "    def configure_optimizers(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Configure the optimizer and learning rate scheduler.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict\n",
    "            Dictionary containing the optimizer and scheduler configuration.\n",
    "        \"\"\"\n",
    "        optimizer = self._get_optimizer()\n",
    "        if self.lr_scheduler is not None:\n",
    "            scheduler = self._get_scheduler(optimizer)\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                return {\n",
    "                    \"optimizer\": optimizer,\n",
    "                    \"lr_scheduler\": {\n",
    "                        \"scheduler\": scheduler,\n",
    "                        \"monitor\": \"val_loss\",\n",
    "                    },\n",
    "                }\n",
    "            else:\n",
    "                return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        return {\"optimizer\": optimizer}\n",
    "\n",
    "    def _get_optimizer(self) -> Optimizer:\n",
    "        \"\"\"\n",
    "        Get the optimizer based on the specified optimizer name and parameters.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Optimizer\n",
    "            The optimizer instance.\n",
    "        \"\"\"\n",
    "        if isinstance(self.optimizer, str):\n",
    "            if self.optimizer.lower() == \"adam\":\n",
    "                return torch.optim.Adam(self.parameters(), **self.optimizer_params)\n",
    "            elif self.optimizer.lower() == \"sgd\":\n",
    "                return torch.optim.SGD(self.parameters(), **self.optimizer_params)\n",
    "            else:\n",
    "                raise ValueError(f\"Optimizer {self.optimizer} not supported.\")\n",
    "        elif isinstance(self.optimizer, Optimizer):\n",
    "            return self.optimizer\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Optimizer must be either a string or \"\n",
    "                \"an instance of torch.optim.Optimizer.\"\n",
    "            )\n",
    "\n",
    "    def _get_scheduler(\n",
    "        self, optimizer: Optimizer\n",
    "    ) -> torch.optim.lr_scheduler._LRScheduler:\n",
    "        \"\"\"\n",
    "        Get the lr scheduler based on the specified scheduler name and params.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        optimizer : Optimizer\n",
    "            The optimizer instance.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.optim.lr_scheduler._LRScheduler\n",
    "            The learning rate scheduler instance.\n",
    "        \"\"\"\n",
    "        if self.lr_scheduler.lower() == \"reduce_lr_on_plateau\":\n",
    "            return torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, **self.lr_scheduler_params\n",
    "            )\n",
    "        elif self.lr_scheduler.lower() == \"step_lr\":\n",
    "            return torch.optim.lr_scheduler.StepLR(\n",
    "                optimizer, **self.lr_scheduler_params\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Scheduler {self.lr_scheduler} not supported.\")\n",
    "\n",
    "    def log_metrics(\n",
    "        self, y_hat: torch.Tensor, y: torch.Tensor, prefix: str = \"val\"\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Log additional metrics during training, validation, or testing.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_hat : torch.Tensor\n",
    "            Predicted output tensor.\n",
    "        y : torch.Tensor\n",
    "            Target output tensor.\n",
    "        prefix : str\n",
    "            Prefix for the logged metrics (e.g., \"train\", \"val\", \"test\").\n",
    "        \"\"\"\n",
    "        for metric in self.logging_metrics:\n",
    "            metric_value = metric(y_hat, y)\n",
    "            self.log(\n",
    "                f\"{prefix}_{metric.__class__.__name__}\",\n",
    "                metric_value,\n",
    "                on_step=False,\n",
    "                on_epoch=True,\n",
    "                prog_bar=True,\n",
    "                logger=True,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5EBeGucK_k0"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "class TFT(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        loss: nn.Module,\n",
    "        logging_metrics: Optional[List[nn.Module]] = None,\n",
    "        optimizer: Optional[Union[Optimizer, str]] = \"adam\",\n",
    "        optimizer_params: Optional[Dict] = None,\n",
    "        lr_scheduler: Optional[str] = None,\n",
    "        lr_scheduler_params: Optional[Dict] = None,\n",
    "        hidden_size: int = 64,\n",
    "        num_layers: int = 2,\n",
    "        attention_head_size: int = 4,\n",
    "        dropout: float = 0.1,\n",
    "        metadata: Optional[Dict] = None,\n",
    "        output_size: int = 1,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            loss=loss,\n",
    "            logging_metrics=logging_metrics,\n",
    "            optimizer=optimizer,\n",
    "            optimizer_params=optimizer_params,\n",
    "            lr_scheduler=lr_scheduler,\n",
    "            lr_scheduler_params=lr_scheduler_params,\n",
    "        )\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.attention_head_size = attention_head_size\n",
    "        self.dropout = dropout\n",
    "        self.metadata = metadata\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.max_encoder_length = self.metadata[\"max_encoder_length\"]\n",
    "        self.max_prediction_length = self.metadata[\"max_prediction_length\"]\n",
    "        self.encoder_cont = self.metadata[\"encoder_cont\"]\n",
    "        self.encoder_cat = self.metadata[\"encoder_cat\"]\n",
    "        self.static_categorical_features = self.metadata[\"static_categorical_features\"]\n",
    "        self.static_continuous_features = self.metadata[\"static_continuous_features\"]\n",
    "\n",
    "        total_feature_size = self.encoder_cont + self.encoder_cat\n",
    "        total_static_size = (\n",
    "            self.static_categorical_features + self.static_continuous_features\n",
    "        )\n",
    "\n",
    "        self.encoder_var_selection = nn.Sequential(\n",
    "            nn.Linear(total_feature_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, total_feature_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        self.decoder_var_selection = nn.Sequential(\n",
    "            nn.Linear(total_feature_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, total_feature_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        self.static_context_linear = (\n",
    "            nn.Linear(total_static_size, hidden_size) if total_static_size > 0 else None\n",
    "        )\n",
    "\n",
    "        self.lstm_encoder = nn.LSTM(\n",
    "            input_size=total_feature_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.lstm_decoder = nn.LSTM(\n",
    "            input_size=total_feature_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.self_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=attention_head_size,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.pre_output = nn.Linear(hidden_size, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass of the TFT model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : Dict[str, torch.Tensor]\n",
    "            Dictionary containing input tensors:\n",
    "            - encoder_cat: Categorical encoder features\n",
    "            - encoder_cont: Continuous encoder features\n",
    "            - decoder_cat: Categorical decoder features\n",
    "            - decoder_cont: Continuous decoder features\n",
    "            - static_categorical_features: Static categorical features\n",
    "            - static_continuous_features: Static continuous features\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, torch.Tensor]\n",
    "            Dictionary containing output tensors:\n",
    "            - prediction: Prediction output (batch_size, prediction_length, output_size)\n",
    "        \"\"\"\n",
    "        batch_size = x[\"encoder_cont\"].shape[0]\n",
    "\n",
    "        encoder_cat = x.get(\n",
    "            \"encoder_cat\",\n",
    "            torch.zeros(batch_size, self.max_encoder_length, 0, device=self.device),\n",
    "        )\n",
    "        encoder_cont = x.get(\n",
    "            \"encoder_cont\",\n",
    "            torch.zeros(batch_size, self.max_encoder_length, 0, device=self.device),\n",
    "        )\n",
    "        decoder_cat = x.get(\n",
    "            \"decoder_cat\",\n",
    "            torch.zeros(batch_size, self.max_prediction_length, 0, device=self.device),\n",
    "        )\n",
    "        decoder_cont = x.get(\n",
    "            \"decoder_cont\",\n",
    "            torch.zeros(batch_size, self.max_prediction_length, 0, device=self.device),\n",
    "        )\n",
    "\n",
    "        encoder_input = torch.cat([encoder_cont, encoder_cat], dim=2)\n",
    "        decoder_input = torch.cat([decoder_cont, decoder_cat], dim=2)\n",
    "\n",
    "        static_context = None\n",
    "        if self.static_context_linear is not None:\n",
    "            static_cat = x.get(\n",
    "                \"static_categorical_features\",\n",
    "                torch.zeros(batch_size, 0, device=self.device),\n",
    "            )\n",
    "            static_cont = x.get(\n",
    "                \"static_continuous_features\",\n",
    "                torch.zeros(batch_size, 0, device=self.device),\n",
    "            )\n",
    "\n",
    "            if static_cat.size(2) == 0 and static_cont.size(2) == 0:\n",
    "                static_context = None\n",
    "            elif static_cat.size(2) == 0:\n",
    "                static_input = static_cont.to(\n",
    "                    dtype=self.static_context_linear.weight.dtype\n",
    "                )\n",
    "                static_context = self.static_context_linear(static_input)\n",
    "                static_context = static_context.view(batch_size, self.hidden_size)\n",
    "            elif static_cont.size(2) == 0:\n",
    "                static_input = static_cat.to(\n",
    "                    dtype=self.static_context_linear.weight.dtype\n",
    "                )\n",
    "                static_context = self.static_context_linear(static_input)\n",
    "                static_context = static_context.view(batch_size, self.hidden_size)\n",
    "            else:\n",
    "\n",
    "                static_input = torch.cat([static_cont, static_cat], dim=1).to(\n",
    "                    dtype=self.static_context_linear.weight.dtype\n",
    "                )\n",
    "                static_context = self.static_context_linear(static_input)\n",
    "                static_context = static_context.view(batch_size, self.hidden_size)\n",
    "\n",
    "        encoder_weights = self.encoder_var_selection(encoder_input)\n",
    "        encoder_input = encoder_input * encoder_weights\n",
    "\n",
    "        decoder_weights = self.decoder_var_selection(decoder_input)\n",
    "        decoder_input = decoder_input * decoder_weights\n",
    "\n",
    "        if static_context is not None:\n",
    "            encoder_static_context = static_context.unsqueeze(1).expand(\n",
    "                -1, self.max_encoder_length, -1\n",
    "            )\n",
    "            decoder_static_context = static_context.unsqueeze(1).expand(\n",
    "                -1, self.max_prediction_length, -1\n",
    "            )\n",
    "\n",
    "            encoder_output, (h_n, c_n) = self.lstm_encoder(encoder_input)\n",
    "            encoder_output = encoder_output + encoder_static_context\n",
    "            decoder_output, _ = self.lstm_decoder(decoder_input, (h_n, c_n))\n",
    "            decoder_output = decoder_output + decoder_static_context\n",
    "        else:\n",
    "            encoder_output, (h_n, c_n) = self.lstm_encoder(encoder_input)\n",
    "            decoder_output, _ = self.lstm_decoder(decoder_input, (h_n, c_n))\n",
    "\n",
    "        sequence = torch.cat([encoder_output, decoder_output], dim=1)\n",
    "\n",
    "        if static_context is not None:\n",
    "            expanded_static_context = static_context.unsqueeze(1).expand(\n",
    "                -1, sequence.size(1), -1\n",
    "            )\n",
    "\n",
    "            attended_output, _ = self.self_attention(\n",
    "                sequence + expanded_static_context, sequence, sequence\n",
    "            )\n",
    "        else:\n",
    "            attended_output, _ = self.self_attention(sequence, sequence, sequence)\n",
    "\n",
    "        decoder_attended = attended_output[:, -self.max_prediction_length :, :]\n",
    "\n",
    "        output = nn.functional.relu(self.pre_output(decoder_attended))\n",
    "        prediction = self.output_layer(output)\n",
    "\n",
    "        return {\"prediction\": prediction}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f422383b4af64a26b16842297d5c84a6",
      "51455b67f5e741b192b5b832aff3d3d3",
      "ccd9a65e258244f4bd29c741c3cb4441",
      "8b5d5e147c8142328d30e2492b57e2c1",
      "3529aafd3f884efe8ba4bb3e33a05c5c",
      "3852c1b855934e6e862ceaf37a855700",
      "5ad79ce792314292a0425b6f03b85881",
      "e9dcea6508f344caa5f1f99e2bfdd4db",
      "2b8d1923ff3145789f77661364163cd1",
      "2b2eb8cd85ba4c16aefa42634b5458cb",
      "edc278a53bb74140ad1a416406f0b0bb",
      "7b4b93e92400404abfd2c31129cda96f",
      "35e7d924e4e44ceaad836bde8fef17d8",
      "6922f0547118463e9468196bf9b1a5c2",
      "119506368b47405786c806373b0bb67d",
      "27ec3bfc950847afb2850ad9ea9bdd49",
      "1016ad0f475740ef9e2d5054323d22e7",
      "b232c9df604a4ce59f422cf60499605f",
      "f9cb515fd148446ca5fcb47fab504a74",
      "adf882d15ee84b2aa3ad6145e2c913bf",
      "f9b429aef6904d6995836f1c1279d38d",
      "8151f2de21b44422876341b10e6b8568",
      "8e46e7b0ea3b429293dc6358980dffe2",
      "831387d48f5f4b8cb0662c5df77aefa4",
      "d08f30db32ec440f94d88727adfc3ee6",
      "9dd7c13be6a54e6b843ccb8afd59fb6b",
      "2db1853b41104999ab6884b33b217f0b",
      "b868fe32ecc44b50b823ae533755a8ef",
      "0d2d00cf7992454484dfd939928aca14",
      "f6131d3c810442c5ad4f71177dac1f5e",
      "8997cb6735c341bc985d4aacb6e20999",
      "df6002b4a12a49fe8d62210c5ebd5b06",
      "adaafe80e3ee4a5c8d6d987800630f2e",
      "2828e899a43b4f17b0bd7c86a701152b",
      "059bbf019de944fda861994e0e7439dd",
      "197c1200910e4256945d64dd9ab33902",
      "4a22ad1ba0c240a3af31a06d117220fb",
      "3ac302bd9b054b9dbe0b76ba7575db68",
      "78f9afd80d634c08965990e66297e5b6",
      "b791ccce40544f6ba57198a0392df981",
      "bff2fcab4d574dc0bcc7382a17f6b080",
      "607dc1dee95147f4a39b16170a08f780",
      "0c40053cf7ba496d87691bfeee0975e4",
      "7b989ec8edc148cb9c3e58aa61637a3b",
      "94a5cc9098f5445593b3212857bd0da2",
      "c236df5d6fdf4bd1b9fdf687819bdffb",
      "e3fcdbd89eb64510b3ed6947d728de1f",
      "52a0d1617601472590aa3b5641236890",
      "ef103e08597e424a81ff70060b4edc77",
      "d25815a46ca64bbea97e6b7f4fff954a",
      "3eb0147ac4d345faae3713d64eb0e66c",
      "a561990cc8204ef08effecce2855a882",
      "afd962bafddc4be2b6ec83067402a19a",
      "c9de18b7a60148e1b35c0dfb0b20e0d5",
      "5f4abc4cadbc4fc7aae645d53f2a03aa",
      "02a2df129afd4ec5a0e6a11ad8d67ee3",
      "eb40207588114030aeb2e66e6a66858b",
      "344cd98e1e4f49dba72ad6df49695e1d",
      "4f5df150e0044ee798c04fa2c722f6c0",
      "5307c74c93dc472bbeeb88e6bfb487f1",
      "8792c8ef2b3d43748b0062327d901bb3",
      "fa845f388d7844a388f079d7cb115824",
      "3d59af9594a445d68dbcc8e51994fcbf",
      "fb7a0d9d587e4806a7519d9201f7f0aa",
      "13d0c7ce5a394744a44439556d43d24d",
      "d09998b10967447e917c8ac88abf26db",
      "e03f176873e6485a91118a9cb4d7fa4d",
      "3866642b5f6c4eaa8f3982da9efa2a4b",
      "fb1c1f0130934f24b163d87846f4210c",
      "0c32b264b85b437f825531554a51e7e1",
      "056e8d3d437c40c889f19e316fbd38ac",
      "f2fb8e95caad4be792063e44a9401f2c",
      "46fd6f7300514bd9b11abeafc51970ec",
      "642bce0f7ab848459f4b5c91068113d4",
      "dc1b070cf7bd43ed8c422e2c1cec6438",
      "2fad0082ed35466caaf6948f6ff4aac0",
      "2d9cd71eec004370b5780a7814d4dd7b",
      "db2a9324292e415e8765117e3dab8356",
      "fae0d1779ea045108616dad057ed24e1",
      "d22ee6b52bbf45bdbe05eb3c23b966c9",
      "e579bbd44a5241f7a7fa027147295ec3",
      "9eb0c593adf7413da7a4abeec48af166",
      "57cb9f2255e4487383465ea0a438a01b",
      "b3d493c1744248fc92301d57dcc07fe9",
      "c8ddbeb5fdb9447c88561abb59edac29",
      "6fd91510b57043c093e4a1fd8302fec3",
      "e623887237994d72bfbff0fb2d76e697",
      "debe1c18531a401e8e3e93791787e1f8"
     ]
    },
    "id": "Si7bbZIULBZz",
    "outputId": "8c1308d6-c1b3-4a67-f56c-f11c225b592c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "INFO: GPU available: False, used: False\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO: \n",
      "  | Name                  | Type               | Params | Mode \n",
      "---------------------------------------------------------------------\n",
      "0 | loss                  | MSELoss            | 0      | train\n",
      "1 | encoder_var_selection | Sequential         | 709    | train\n",
      "2 | decoder_var_selection | Sequential         | 709    | train\n",
      "3 | static_context_linear | Linear             | 192    | train\n",
      "4 | lstm_encoder          | LSTM               | 51.5 K | train\n",
      "5 | lstm_decoder          | LSTM               | 51.5 K | train\n",
      "6 | self_attention        | MultiheadAttention | 16.6 K | train\n",
      "7 | pre_output            | Linear             | 4.2 K  | train\n",
      "8 | output_layer          | Linear             | 65     | train\n",
      "---------------------------------------------------------------------\n",
      "125 K     Trainable params\n",
      "0         Non-trainable params\n",
      "125 K     Total params\n",
      "0.502     Total estimated model params size (MB)\n",
      "18        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name                  | Type               | Params | Mode \n",
      "---------------------------------------------------------------------\n",
      "0 | loss                  | MSELoss            | 0      | train\n",
      "1 | encoder_var_selection | Sequential         | 709    | train\n",
      "2 | decoder_var_selection | Sequential         | 709    | train\n",
      "3 | static_context_linear | Linear             | 192    | train\n",
      "4 | lstm_encoder          | LSTM               | 51.5 K | train\n",
      "5 | lstm_decoder          | LSTM               | 51.5 K | train\n",
      "6 | self_attention        | MultiheadAttention | 16.6 K | train\n",
      "7 | pre_output            | Linear             | 4.2 K  | train\n",
      "8 | output_layer          | Linear             | 65     | train\n",
      "---------------------------------------------------------------------\n",
      "125 K     Trainable params\n",
      "0         Non-trainable params\n",
      "125 K     Total params\n",
      "0.502     Total estimated model params size (MB)\n",
      "18        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f422383b4af64a26b16842297d5c84a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (42) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4b93e92400404abfd2c31129cda96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e46e7b0ea3b429293dc6358980dffe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2828e899a43b4f17b0bd7c86a701152b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a5cc9098f5445593b3212857bd0da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a2df129afd4ec5a0e6a11ad8d67ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03f176873e6485a91118a9cb4d7fa4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2a9324292e415e8765117e3dab8356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_MAE          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4572468101978302     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_SMAPE         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0497652292251587     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.022910255938768387    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_MAE         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4572468101978302    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_SMAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0497652292251587    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.022910255938768387   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction shape: torch.Size([32, 1, 1])\n",
      "First prediction values: [[-0.06341379]]\n",
      "First true values: [[0.08132173]]\n",
      "\n",
      "TFT model test complete!\n"
     ]
    }
   ],
   "source": [
    "model = TFT(\n",
    "    loss=nn.MSELoss(),\n",
    "    logging_metrics=[MAE(), SMAPE()],\n",
    "    optimizer=\"adam\",\n",
    "    optimizer_params={\"lr\": 1e-3},\n",
    "    lr_scheduler=\"reduce_lr_on_plateau\",\n",
    "    lr_scheduler_params={\"mode\": \"min\", \"factor\": 0.1, \"patience\": 10},\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    metadata=data_module.metadata,\n",
    ")\n",
    "\n",
    "print(\"\\nTraining model...\")\n",
    "trainer = Trainer(max_epochs=5, accelerator=\"auto\", devices=1, enable_progress_bar=True)\n",
    "\n",
    "trainer.fit(model, data_module)\n",
    "\n",
    "print(\"\\nEvaluating model...\")\n",
    "test_metrics = trainer.test(model, data_module)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_batch = next(iter(data_module.test_dataloader()))\n",
    "    x_test, y_test = test_batch\n",
    "    y_pred = model(x_test)\n",
    "\n",
    "    print(\"\\nPrediction shape:\", y_pred[\"prediction\"].shape)\n",
    "    print(\"First prediction values:\", y_pred[\"prediction\"][0].cpu().numpy())\n",
    "    print(\"First true values:\", y_test[0].cpu().numpy())\n",
    "print(\"\\nTFT model test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVRwi2MvLGgc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02a2df129afd4ec5a0e6a11ad8d67ee3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eb40207588114030aeb2e66e6a66858b",
       "IPY_MODEL_344cd98e1e4f49dba72ad6df49695e1d",
       "IPY_MODEL_4f5df150e0044ee798c04fa2c722f6c0"
      ],
      "layout": "IPY_MODEL_5307c74c93dc472bbeeb88e6bfb487f1"
     }
    },
    "056e8d3d437c40c889f19e316fbd38ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "059bbf019de944fda861994e0e7439dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78f9afd80d634c08965990e66297e5b6",
      "placeholder": "​",
      "style": "IPY_MODEL_b791ccce40544f6ba57198a0392df981",
      "value": "Validation DataLoader 0: 100%"
     }
    },
    "0c32b264b85b437f825531554a51e7e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2fad0082ed35466caaf6948f6ff4aac0",
      "placeholder": "​",
      "style": "IPY_MODEL_2d9cd71eec004370b5780a7814d4dd7b",
      "value": " 9/9 [00:00&lt;00:00, 31.33it/s]"
     }
    },
    "0c40053cf7ba496d87691bfeee0975e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d2d00cf7992454484dfd939928aca14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1016ad0f475740ef9e2d5054323d22e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "119506368b47405786c806373b0bb67d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9b429aef6904d6995836f1c1279d38d",
      "placeholder": "​",
      "style": "IPY_MODEL_8151f2de21b44422876341b10e6b8568",
      "value": " 42/42 [00:02&lt;00:00, 15.49it/s, v_num=2, train_loss_step=0.010, val_loss=0.0243, val_MAE=0.477, val_SMAPE=1.120, train_loss_epoch=0.0156, train_MAE=0.480, train_SMAPE=1.020]"
     }
    },
    "13d0c7ce5a394744a44439556d43d24d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "197c1200910e4256945d64dd9ab33902": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bff2fcab4d574dc0bcc7382a17f6b080",
      "max": 9,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_607dc1dee95147f4a39b16170a08f780",
      "value": 9
     }
    },
    "27ec3bfc950847afb2850ad9ea9bdd49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "2828e899a43b4f17b0bd7c86a701152b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_059bbf019de944fda861994e0e7439dd",
       "IPY_MODEL_197c1200910e4256945d64dd9ab33902",
       "IPY_MODEL_4a22ad1ba0c240a3af31a06d117220fb"
      ],
      "layout": "IPY_MODEL_3ac302bd9b054b9dbe0b76ba7575db68"
     }
    },
    "2b2eb8cd85ba4c16aefa42634b5458cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b8d1923ff3145789f77661364163cd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2d9cd71eec004370b5780a7814d4dd7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2db1853b41104999ab6884b33b217f0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "2fad0082ed35466caaf6948f6ff4aac0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "344cd98e1e4f49dba72ad6df49695e1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d59af9594a445d68dbcc8e51994fcbf",
      "max": 9,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fb7a0d9d587e4806a7519d9201f7f0aa",
      "value": 9
     }
    },
    "3529aafd3f884efe8ba4bb3e33a05c5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "35e7d924e4e44ceaad836bde8fef17d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1016ad0f475740ef9e2d5054323d22e7",
      "placeholder": "​",
      "style": "IPY_MODEL_b232c9df604a4ce59f422cf60499605f",
      "value": "Epoch 4: 100%"
     }
    },
    "3852c1b855934e6e862ceaf37a855700": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3866642b5f6c4eaa8f3982da9efa2a4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2fb8e95caad4be792063e44a9401f2c",
      "placeholder": "​",
      "style": "IPY_MODEL_46fd6f7300514bd9b11abeafc51970ec",
      "value": "Validation DataLoader 0: 100%"
     }
    },
    "3ac302bd9b054b9dbe0b76ba7575db68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "3d59af9594a445d68dbcc8e51994fcbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3eb0147ac4d345faae3713d64eb0e66c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "46fd6f7300514bd9b11abeafc51970ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a22ad1ba0c240a3af31a06d117220fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c40053cf7ba496d87691bfeee0975e4",
      "placeholder": "​",
      "style": "IPY_MODEL_7b989ec8edc148cb9c3e58aa61637a3b",
      "value": " 9/9 [00:00&lt;00:00, 25.66it/s]"
     }
    },
    "4f5df150e0044ee798c04fa2c722f6c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13d0c7ce5a394744a44439556d43d24d",
      "placeholder": "​",
      "style": "IPY_MODEL_d09998b10967447e917c8ac88abf26db",
      "value": " 9/9 [00:00&lt;00:00, 32.96it/s]"
     }
    },
    "51455b67f5e741b192b5b832aff3d3d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3852c1b855934e6e862ceaf37a855700",
      "placeholder": "​",
      "style": "IPY_MODEL_5ad79ce792314292a0425b6f03b85881",
      "value": "Sanity Checking DataLoader 0: 100%"
     }
    },
    "52a0d1617601472590aa3b5641236890": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9de18b7a60148e1b35c0dfb0b20e0d5",
      "placeholder": "​",
      "style": "IPY_MODEL_5f4abc4cadbc4fc7aae645d53f2a03aa",
      "value": " 9/9 [00:00&lt;00:00, 34.85it/s]"
     }
    },
    "5307c74c93dc472bbeeb88e6bfb487f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "57cb9f2255e4487383465ea0a438a01b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ad79ce792314292a0425b6f03b85881": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f4abc4cadbc4fc7aae645d53f2a03aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "607dc1dee95147f4a39b16170a08f780": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "642bce0f7ab848459f4b5c91068113d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6922f0547118463e9468196bf9b1a5c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9cb515fd148446ca5fcb47fab504a74",
      "max": 42,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_adf882d15ee84b2aa3ad6145e2c913bf",
      "value": 42
     }
    },
    "6fd91510b57043c093e4a1fd8302fec3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "78f9afd80d634c08965990e66297e5b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b4b93e92400404abfd2c31129cda96f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_35e7d924e4e44ceaad836bde8fef17d8",
       "IPY_MODEL_6922f0547118463e9468196bf9b1a5c2",
       "IPY_MODEL_119506368b47405786c806373b0bb67d"
      ],
      "layout": "IPY_MODEL_27ec3bfc950847afb2850ad9ea9bdd49"
     }
    },
    "7b989ec8edc148cb9c3e58aa61637a3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8151f2de21b44422876341b10e6b8568": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "831387d48f5f4b8cb0662c5df77aefa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b868fe32ecc44b50b823ae533755a8ef",
      "placeholder": "​",
      "style": "IPY_MODEL_0d2d00cf7992454484dfd939928aca14",
      "value": "Validation DataLoader 0: 100%"
     }
    },
    "8792c8ef2b3d43748b0062327d901bb3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8997cb6735c341bc985d4aacb6e20999": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8b5d5e147c8142328d30e2492b57e2c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b2eb8cd85ba4c16aefa42634b5458cb",
      "placeholder": "​",
      "style": "IPY_MODEL_edc278a53bb74140ad1a416406f0b0bb",
      "value": " 2/2 [00:00&lt;00:00, 21.87it/s]"
     }
    },
    "8e46e7b0ea3b429293dc6358980dffe2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_831387d48f5f4b8cb0662c5df77aefa4",
       "IPY_MODEL_d08f30db32ec440f94d88727adfc3ee6",
       "IPY_MODEL_9dd7c13be6a54e6b843ccb8afd59fb6b"
      ],
      "layout": "IPY_MODEL_2db1853b41104999ab6884b33b217f0b"
     }
    },
    "94a5cc9098f5445593b3212857bd0da2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c236df5d6fdf4bd1b9fdf687819bdffb",
       "IPY_MODEL_e3fcdbd89eb64510b3ed6947d728de1f",
       "IPY_MODEL_52a0d1617601472590aa3b5641236890"
      ],
      "layout": "IPY_MODEL_ef103e08597e424a81ff70060b4edc77"
     }
    },
    "9dd7c13be6a54e6b843ccb8afd59fb6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df6002b4a12a49fe8d62210c5ebd5b06",
      "placeholder": "​",
      "style": "IPY_MODEL_adaafe80e3ee4a5c8d6d987800630f2e",
      "value": " 9/9 [00:00&lt;00:00, 33.87it/s]"
     }
    },
    "9eb0c593adf7413da7a4abeec48af166": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "a561990cc8204ef08effecce2855a882": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "adaafe80e3ee4a5c8d6d987800630f2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "adf882d15ee84b2aa3ad6145e2c913bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "afd962bafddc4be2b6ec83067402a19a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b232c9df604a4ce59f422cf60499605f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3d493c1744248fc92301d57dcc07fe9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b791ccce40544f6ba57198a0392df981": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b868fe32ecc44b50b823ae533755a8ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bff2fcab4d574dc0bcc7382a17f6b080": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c236df5d6fdf4bd1b9fdf687819bdffb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d25815a46ca64bbea97e6b7f4fff954a",
      "placeholder": "​",
      "style": "IPY_MODEL_3eb0147ac4d345faae3713d64eb0e66c",
      "value": "Validation DataLoader 0: 100%"
     }
    },
    "c8ddbeb5fdb9447c88561abb59edac29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9de18b7a60148e1b35c0dfb0b20e0d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccd9a65e258244f4bd29c741c3cb4441": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9dcea6508f344caa5f1f99e2bfdd4db",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2b8d1923ff3145789f77661364163cd1",
      "value": 2
     }
    },
    "d08f30db32ec440f94d88727adfc3ee6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6131d3c810442c5ad4f71177dac1f5e",
      "max": 9,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8997cb6735c341bc985d4aacb6e20999",
      "value": 9
     }
    },
    "d09998b10967447e917c8ac88abf26db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d22ee6b52bbf45bdbe05eb3c23b966c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8ddbeb5fdb9447c88561abb59edac29",
      "max": 9,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6fd91510b57043c093e4a1fd8302fec3",
      "value": 9
     }
    },
    "d25815a46ca64bbea97e6b7f4fff954a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db2a9324292e415e8765117e3dab8356": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fae0d1779ea045108616dad057ed24e1",
       "IPY_MODEL_d22ee6b52bbf45bdbe05eb3c23b966c9",
       "IPY_MODEL_e579bbd44a5241f7a7fa027147295ec3"
      ],
      "layout": "IPY_MODEL_9eb0c593adf7413da7a4abeec48af166"
     }
    },
    "dc1b070cf7bd43ed8c422e2c1cec6438": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "debe1c18531a401e8e3e93791787e1f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df6002b4a12a49fe8d62210c5ebd5b06": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e03f176873e6485a91118a9cb4d7fa4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3866642b5f6c4eaa8f3982da9efa2a4b",
       "IPY_MODEL_fb1c1f0130934f24b163d87846f4210c",
       "IPY_MODEL_0c32b264b85b437f825531554a51e7e1"
      ],
      "layout": "IPY_MODEL_056e8d3d437c40c889f19e316fbd38ac"
     }
    },
    "e3fcdbd89eb64510b3ed6947d728de1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a561990cc8204ef08effecce2855a882",
      "max": 9,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_afd962bafddc4be2b6ec83067402a19a",
      "value": 9
     }
    },
    "e579bbd44a5241f7a7fa027147295ec3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e623887237994d72bfbff0fb2d76e697",
      "placeholder": "​",
      "style": "IPY_MODEL_debe1c18531a401e8e3e93791787e1f8",
      "value": " 9/9 [00:00&lt;00:00, 33.35it/s]"
     }
    },
    "e623887237994d72bfbff0fb2d76e697": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9dcea6508f344caa5f1f99e2bfdd4db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb40207588114030aeb2e66e6a66858b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8792c8ef2b3d43748b0062327d901bb3",
      "placeholder": "​",
      "style": "IPY_MODEL_fa845f388d7844a388f079d7cb115824",
      "value": "Validation DataLoader 0: 100%"
     }
    },
    "edc278a53bb74140ad1a416406f0b0bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef103e08597e424a81ff70060b4edc77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "f2fb8e95caad4be792063e44a9401f2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f422383b4af64a26b16842297d5c84a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_51455b67f5e741b192b5b832aff3d3d3",
       "IPY_MODEL_ccd9a65e258244f4bd29c741c3cb4441",
       "IPY_MODEL_8b5d5e147c8142328d30e2492b57e2c1"
      ],
      "layout": "IPY_MODEL_3529aafd3f884efe8ba4bb3e33a05c5c"
     }
    },
    "f6131d3c810442c5ad4f71177dac1f5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9b429aef6904d6995836f1c1279d38d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9cb515fd148446ca5fcb47fab504a74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa845f388d7844a388f079d7cb115824": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fae0d1779ea045108616dad057ed24e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57cb9f2255e4487383465ea0a438a01b",
      "placeholder": "​",
      "style": "IPY_MODEL_b3d493c1744248fc92301d57dcc07fe9",
      "value": "Testing DataLoader 0: 100%"
     }
    },
    "fb1c1f0130934f24b163d87846f4210c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_642bce0f7ab848459f4b5c91068113d4",
      "max": 9,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dc1b070cf7bd43ed8c422e2c1cec6438",
      "value": 9
     }
    },
    "fb7a0d9d587e4806a7519d9201f7f0aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
