{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5d44943",
   "metadata": {},
   "source": [
    "# TSLib for v2 - Example notebook for full pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d27b55",
   "metadata": {},
   "source": [
    "## Basic imports for getting started\n",
    "\n",
    "This notebook is a basic vignette for the usage of the `tslib` data module on the `TimeXer` model for the v2 of PyTorch Forecasting. This is an experimental version and is an unstable version of the API.\n",
    "\n",
    "Feedback and suggestions on this pipeline - PR [#1836](https://github.com/sktime/pytorch-forecasting/pull/1836)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "import torch\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from pytorch_forecasting.data._tslib_data_module import TslibDataModule\n",
    "from pytorch_forecasting.data.encoders import (\n",
    "    EncoderNormalizer,\n",
    "    NaNLabelEncoder,\n",
    "    TorchNormalizer,\n",
    ")\n",
    "from pytorch_forecasting.data.timeseries import TimeSeries\n",
    "from pytorch_forecasting.models.timexer._timexer_v2 import TimeXer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2625ed3d",
   "metadata": {},
   "source": [
    "## Construct a time series dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0058487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "series_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time_idx",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "category",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "future_known_feature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "static_feature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "static_feature_cat",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "c9857045-a68d-4ffa-88c5-5a89d998296b",
       "rows": [
        [
         "0",
         "0",
         "0",
         "-0.053473564791053224",
         "0.07936543423104955",
         "0",
         "1.0",
         "0.07624037564165775",
         "0"
        ],
        [
         "1",
         "0",
         "1",
         "0.07936543423104955",
         "0.47510107923326006",
         "0",
         "0.9950041652780258",
         "0.07624037564165775",
         "0"
        ],
        [
         "2",
         "0",
         "2",
         "0.47510107923326006",
         "0.5532736977674955",
         "0",
         "0.9800665778412416",
         "0.07624037564165775",
         "0"
        ],
        [
         "3",
         "0",
         "3",
         "0.5532736977674955",
         "0.5934601539777484",
         "0",
         "0.955336489125606",
         "0.07624037564165775",
         "0"
        ],
        [
         "4",
         "0",
         "4",
         "0.5934601539777484",
         "0.999893228642273",
         "0",
         "0.9210609940028851",
         "0.07624037564165775",
         "0"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>category</th>\n",
       "      <th>future_known_feature</th>\n",
       "      <th>static_feature</th>\n",
       "      <th>static_feature_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.053474</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.07624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.475101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995004</td>\n",
       "      <td>0.07624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.475101</td>\n",
       "      <td>0.553274</td>\n",
       "      <td>0</td>\n",
       "      <td>0.980067</td>\n",
       "      <td>0.07624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.553274</td>\n",
       "      <td>0.593460</td>\n",
       "      <td>0</td>\n",
       "      <td>0.955336</td>\n",
       "      <td>0.07624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.593460</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0</td>\n",
       "      <td>0.921061</td>\n",
       "      <td>0.07624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id  time_idx         x         y  category  future_known_feature  \\\n",
       "0          0         0 -0.053474  0.079365         0              1.000000   \n",
       "1          0         1  0.079365  0.475101         0              0.995004   \n",
       "2          0         2  0.475101  0.553274         0              0.980067   \n",
       "3          0         3  0.553274  0.593460         0              0.955336   \n",
       "4          0         4  0.593460  0.999893         0              0.921061   \n",
       "\n",
       "   static_feature  static_feature_cat  \n",
       "0         0.07624                   0  \n",
       "1         0.07624                   0  \n",
       "2         0.07624                   0  \n",
       "3         0.07624                   0  \n",
       "4         0.07624                   0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_series = 100\n",
    "seq_length = 50\n",
    "data_list = []\n",
    "for i in range(num_series):\n",
    "    x = np.arange(seq_length)\n",
    "    y = np.sin(x / 5.0) + np.random.normal(scale=0.1, size=seq_length)\n",
    "    category = i % 5\n",
    "    static_value = np.random.rand()\n",
    "    for t in range(seq_length - 1):\n",
    "        data_list.append(\n",
    "            {\n",
    "                \"series_id\": i,\n",
    "                \"time_idx\": t,\n",
    "                \"x\": y[t],\n",
    "                \"y\": y[t + 1],\n",
    "                \"category\": category,\n",
    "                \"future_known_feature\": np.cos(t / 10),\n",
    "                \"static_feature\": static_value,\n",
    "                \"static_feature_cat\": i % 3,\n",
    "            }\n",
    "        )\n",
    "data_df = pd.DataFrame(data_list)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89a5adbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\Desktop\\code\\pytorch-forecasting\\pytorch_forecasting\\data\\timeseries\\_timeseries_v2.py:105: UserWarning: TimeSeries is part of an experimental rework of the pytorch-forecasting data layer, scheduled for release with v2.0.0. The API is not stable and may change without prior warning. For beta testing, but not for stable production use. Feedback and suggestions are very welcome in pytorch-forecasting issue 1736, https://github.com/sktime/pytorch-forecasting/issues/1736\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = TimeSeries(\n",
    "    data=data_df,\n",
    "    time=\"time_idx\",\n",
    "    target=\"y\",\n",
    "    group=[\"series_id\"],\n",
    "    num=[\"x\", \"future_know_feature\", \"static_feature\"],\n",
    "    cat=[\"category\", \"static_feature_cat\"],\n",
    "    known=[\"future_known_feature\"],\n",
    "    unknown=[\"x\", \"category\"],\n",
    "    static=[\"static_feature\", \"static_feature_cat\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8753a6a",
   "metadata": {},
   "source": [
    "## Initialise the `TslibDataModule` using the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eae9035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\Desktop\\code\\pytorch-forecasting\\pytorch_forecasting\\data\\tslib_data_module.py:271: UserWarning: TslibDataModule is experimental and subject to change. The API is not stable and may change without prior warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_module = TslibDataModule(\n",
    "    time_series_dataset=dataset,\n",
    "    context_length=30,\n",
    "    prediction_length=1,\n",
    "    add_relative_time_idx=True,\n",
    "    target_normalizer=TorchNormalizer(),\n",
    "    categorical_encoders={\n",
    "        \"category\": NaNLabelEncoder(add_nan=True),\n",
    "        \"static_feature_cat\": NaNLabelEncoder(add_nan=True),\n",
    "    },\n",
    "    scalers={\n",
    "        \"x\": StandardScaler(),\n",
    "        \"future_known_feature\": StandardScaler(),\n",
    "        \"static_feature\": StandardScaler(),\n",
    "    },\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76ebffc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_module.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1843233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_names': {'categorical': ['category', 'static_feature_cat'],\n",
       "  'continuous': ['x', 'future_known_feature', 'static_feature'],\n",
       "  'static': ['static_feature', 'static_feature_cat'],\n",
       "  'known': ['future_known_feature'],\n",
       "  'unknown': ['x', 'category', 'static_feature', 'static_feature_cat'],\n",
       "  'target': ['y'],\n",
       "  'all': ['x',\n",
       "   'category',\n",
       "   'future_known_feature',\n",
       "   'static_feature',\n",
       "   'static_feature_cat'],\n",
       "  'static_categorical': ['static_feature_cat'],\n",
       "  'static_continuous': ['static_feature']},\n",
       " 'feature_indices': {'categorical': [1, 4],\n",
       "  'continuous': [0, 2, 3],\n",
       "  'static': [],\n",
       "  'known': [2],\n",
       "  'unknown': [0, 1, 3, 4],\n",
       "  'target': [0]},\n",
       " 'n_features': {'categorical': 2,\n",
       "  'continuous': 3,\n",
       "  'static': 2,\n",
       "  'known': 1,\n",
       "  'unknown': 4,\n",
       "  'target': 1,\n",
       "  'all': 5,\n",
       "  'static_categorical': 1,\n",
       "  'static_continuous': 1},\n",
       " 'context_length': 30,\n",
       " 'prediction_length': 1,\n",
       " 'freq': 'h',\n",
       " 'features': 'MS'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12036e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, QuantileLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9451ee",
   "metadata": {},
   "source": [
    "## Initialise the model\n",
    "\n",
    "We shall try out two versions of this model, one using `MAE()` and one with `QuantileLoss()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "429b5f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\Desktop\\code\\pytorch-forecasting\\pytorch_forecasting\\models\\base\\_base_model_v2.py:58: UserWarning: The Model 'TimeXer' is part of an experimental reworkof the pytorch-forecasting model layer, scheduled for release with v2.0.0. The API is not stable and may change without prior warning. This class is intended for beta testing and as a basic skeleton, but not for stable production use. Feedback and suggestions are very welcome in pytorch-forecasting issue 1736, https://github.com/sktime/pytorch-forecasting/issues/1736\n",
      "  warn(\n",
      "C:\\Users\\prana\\Desktop\\code\\pytorch-forecasting\\pytorch_forecasting\\models\\base\\_tslib_base_model_v2.py:60: UserWarning: The Model 'TimeXer' is part of an experimental implementationof the pytorch-forecasting model layer for Time Series Library, scheduledfor release with v2.0.0. The API is not stableand may change without prior warning. This class is intended for betatesting, not for stable production use.\n",
      "  warn(\n",
      "C:\\Users\\prana\\Desktop\\code\\pytorch-forecasting\\pytorch_forecasting\\models\\timexer\\_timexer.py:133: UserWarning: TimeXer is an experimental model implemented on TslibBaseModelV2. It is an unstable version and maybe subject to unannouced changes.Please use with caution. Feedback on the design and implementation iswelcome. On the issue #1833 - https://github.com/sktime/pytorch-forecasting/issues/1833\n",
      "  warn.warn(\n",
      "C:\\Users\\prana\\Desktop\\code\\pytorch-forecasting\\pytorch_forecasting\\models\\timexer\\_timexer.py:180: UserWarning: Context length (30) is not divisible by patch length. This may lead to unexpected behavior, as sometime steps will not be used in the model.\n",
      "  warn.warn(\n"
     ]
    }
   ],
   "source": [
    "model1 = TimeXer(\n",
    "    loss=nn.MSELoss(),\n",
    "    hidden_size=64,\n",
    "    nhead=4,\n",
    "    e_layers=2,\n",
    "    d_ff=256,\n",
    "    dropout=0.1,\n",
    "    patch_length=4,\n",
    "    logging_metrics=[MAE(), SMAPE()],\n",
    "    optimizer=\"adam\",\n",
    "    optimizer_params={\"lr\": 1e-3},\n",
    "    lr_scheduler=\"reduce_lr_on_plateau\",\n",
    "    lr_scheduler_params={\n",
    "        \"mode\": \"min\",\n",
    "        \"factor\": 0.5,\n",
    "        \"patience\": 5,\n",
    "    },\n",
    "    metadata=data_module.metadata,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aa21f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = TimeXer(\n",
    "    loss=QuantileLoss(quantiles=[0.1, 0.5, 0.9]),  # quantiles of 0.1, 0.5 and 0.9 used.\n",
    "    hidden_size=64,\n",
    "    nhead=4,\n",
    "    e_layers=2,\n",
    "    d_ff=256,\n",
    "    dropout=0.1,\n",
    "    patch_length=4,\n",
    "    logging_metrics=[MAE(), SMAPE()],\n",
    "    optimizer=\"adam\",\n",
    "    optimizer_params={\"lr\": 1e-3},\n",
    "    lr_scheduler=\"reduce_lr_on_plateau\",\n",
    "    lr_scheduler_params={\n",
    "        \"mode\": \"min\",\n",
    "        \"factor\": 0.5,\n",
    "        \"patience\": 5,\n",
    "    },\n",
    "    metadata=data_module.metadata,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02605f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "\n",
    "trainer1 = Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    enable_progress_bar=True,\n",
    "    enable_model_summary=True,\n",
    ")\n",
    "\n",
    "trainer2 = Trainer(\n",
    "    max_epochs=4,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    enable_progress_bar=True,\n",
    "    enable_model_summary=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22756b2",
   "metadata": {},
   "source": [
    "## Fit the trainer on the model and feed data using the data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e9117d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 6GB Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type                   | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | loss         | MSELoss                | 0      | train\n",
      "1 | en_embedding | EnEmbedding            | 320    | train\n",
      "2 | ex_embedding | DataEmbedding_inverted | 2.0 K  | train\n",
      "3 | encoder      | Encoder                | 133 K  | train\n",
      "4 | head         | FlattenHead            | 513    | train\n",
      "----------------------------------------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.546     Total estimated model params size (MB)\n",
      "57        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ecfe067c98048e1bd2b47f4299d7fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prana\\Desktop\\code\\pytorch-forecasting\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\prana\\Desktop\\code\\pytorch-forecasting\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\prana\\Desktop\\code\\pytorch-forecasting\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:310: The number of training batches (42) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3a2094bf4545428632f0968fb342c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4d1aad5db94de0bd39efd7f8175525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd6ba99319d48b0b35692aaa4e95310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4737a76040249f19e9623664ecf5ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69834733cbf448282737158fcd36e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ab8deef6f043aea43bad3b6e161b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer1.fit(model1, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb4f31",
   "metadata": {},
   "source": [
    "Now let us train the model using `QuantileLoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c67d86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type                   | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | loss         | QuantileLoss           | 0      | train\n",
      "1 | en_embedding | EnEmbedding            | 320    | train\n",
      "2 | ex_embedding | DataEmbedding_inverted | 2.0 K  | train\n",
      "3 | encoder      | Encoder                | 133 K  | train\n",
      "4 | head         | FlattenHead            | 1.5 K  | train\n",
      "----------------------------------------------------------------\n",
      "137 K     Trainable params\n",
      "0         Non-trainable params\n",
      "137 K     Total params\n",
      "0.550     Total estimated model params size (MB)\n",
      "57        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c37e2e45fe46e983bf8394a32d9b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prana\\Desktop\\code\\pytorch-forecasting\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\prana\\Desktop\\code\\pytorch-forecasting\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\prana\\Desktop\\code\\pytorch-forecasting\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:310: The number of training batches (42) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e174aa2bcce24a27b7a18257de3fdcf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc646a5affc046cbb17acd5374b30843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3341a2a66d2488c8f59ad2a5a7a85a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52729a846571428e8f397c9682524b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a338ea94aa9490b8717c783331a2f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer2.fit(model2, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e2d445",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbf1ace6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\prana\\Desktop\\code\\pytorch-forecasting\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cb4dc5cc1048f68884de161d2e53c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_MAE            0.47346481680870056\n",
      "       test_SMAPE           1.0982568264007568\n",
      "        test_loss           0.01038370467722416\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "test_metrics = trainer1.test(model1, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "250b128a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeXer(\n",
       "  (loss): MSELoss()\n",
       "  (en_embedding): EnEmbedding(\n",
       "    (value_embedding): Linear(in_features=4, out_features=64, bias=False)\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (ex_embedding): DataEmbedding_inverted(\n",
       "    (value_embedding): Linear(in_features=30, out_features=64, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (self_attention): AttentionLayer(\n",
       "          (inner_attention): FullAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (cross_attention): AttentionLayer(\n",
       "          (inner_attention): FullAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (head): FlattenHead(\n",
       "    (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "    (linear): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f730b49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[[-0.0154]],\n",
      "\n",
      "        [[ 0.1871]],\n",
      "\n",
      "        [[ 0.3392]],\n",
      "\n",
      "        [[ 0.4948]],\n",
      "\n",
      "        [[ 0.6630]],\n",
      "\n",
      "        [[ 0.7778]],\n",
      "\n",
      "        [[ 0.8391]],\n",
      "\n",
      "        [[ 0.9001]],\n",
      "\n",
      "        [[ 0.9442]],\n",
      "\n",
      "        [[ 0.9302]],\n",
      "\n",
      "        [[ 0.8536]],\n",
      "\n",
      "        [[ 0.7712]],\n",
      "\n",
      "        [[ 0.6658]],\n",
      "\n",
      "        [[ 0.5068]],\n",
      "\n",
      "        [[ 0.3144]],\n",
      "\n",
      "        [[ 0.1697]],\n",
      "\n",
      "        [[-0.0298]],\n",
      "\n",
      "        [[-0.1914]],\n",
      "\n",
      "        [[-0.3421]],\n",
      "\n",
      "        [[-0.0522]],\n",
      "\n",
      "        [[ 0.1340]],\n",
      "\n",
      "        [[ 0.3186]],\n",
      "\n",
      "        [[ 0.4486]],\n",
      "\n",
      "        [[ 0.5877]],\n",
      "\n",
      "        [[ 0.7270]],\n",
      "\n",
      "        [[ 0.8507]],\n",
      "\n",
      "        [[ 0.9346]],\n",
      "\n",
      "        [[ 0.9891]],\n",
      "\n",
      "        [[ 0.9665]],\n",
      "\n",
      "        [[ 0.9295]],\n",
      "\n",
      "        [[ 0.8394]],\n",
      "\n",
      "        [[ 0.6876]]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_batch = next(iter(data_module.test_dataloader()))\n",
    "    x_test, y_test = test_batch\n",
    "    y_pred = model1(x_test)\n",
    "\n",
    "    print(\"Prediction:\", y_pred[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e316c047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[\"prediction\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01927d4",
   "metadata": {},
   "source": [
    "Let us do the same for `QuantileLoss` predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22bd191f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\prana\\Desktop\\code\\pytorch-forecasting\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988bff58f66d4cc6920ad764610c69c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_MAE            14.938094139099121\n",
      "       test_SMAPE           32.958351135253906\n",
      "        test_loss            7.362493991851807\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "test_metrics = trainer2.test(model2, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1d857db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeXer(\n",
       "  (loss): QuantileLoss(quantiles=[0.1, 0.5, 0.9])\n",
       "  (en_embedding): EnEmbedding(\n",
       "    (value_embedding): Linear(in_features=4, out_features=64, bias=False)\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (ex_embedding): DataEmbedding_inverted(\n",
       "    (value_embedding): Linear(in_features=30, out_features=64, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (self_attention): AttentionLayer(\n",
       "          (inner_attention): FullAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (cross_attention): AttentionLayer(\n",
       "          (inner_attention): FullAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (head): FlattenHead(\n",
       "    (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "    (linear): Linear(in_features=512, out_features=3, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52e2a36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[[[-0.0882, -0.0966,  0.2563]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0720,  0.0759,  0.3883]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1974,  0.2169,  0.5460]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3700,  0.3511,  0.6714]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5103,  0.4835,  0.8189]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6425,  0.6295,  0.9646]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7363,  0.7258,  1.0382]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8186,  0.8055,  1.1244]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8566,  0.8481,  1.1788]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8571,  0.8442,  1.1794]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8222,  0.7861,  1.1303]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7280,  0.6996,  1.0412]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6072,  0.5680,  0.9375]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5022,  0.4539,  0.7923]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3323,  0.3054,  0.6894]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1943,  0.1492,  0.5411]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0051, -0.0246,  0.3653]]],\n",
      "\n",
      "\n",
      "        [[[-0.1639, -0.1800,  0.1996]]],\n",
      "\n",
      "\n",
      "        [[[-0.3275, -0.3510,  0.0374]]],\n",
      "\n",
      "\n",
      "        [[[-0.1448, -0.1228,  0.2111]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0111,  0.0275,  0.3488]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1809,  0.1731,  0.4954]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3314,  0.3016,  0.6251]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4878,  0.4772,  0.7736]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6037,  0.6159,  0.9321]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7124,  0.7119,  1.0446]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7932,  0.7615,  1.1003]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8380,  0.8052,  1.1551]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8486,  0.8086,  1.1488]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8270,  0.7949,  1.1258]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7602,  0.7362,  1.0832]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6516,  0.6263,  0.9960]]]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_batch = next(iter(data_module.test_dataloader()))\n",
    "    x_test, y_test = test_batch\n",
    "    y_pred = model2(x_test)\n",
    "\n",
    "    print(\"Prediction:\", y_pred[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4e6e4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 1, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[\"prediction\"].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
